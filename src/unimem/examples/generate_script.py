"""
çŸ­å‰§å‰§æœ¬ç”Ÿæˆè„šæœ¬

ä½¿ç”¨ ScriptAdapter ç”Ÿæˆ50é›†çŸ­å‰§å‰§æœ¬
æµç¨‹ï¼šå¤§çº² -> åˆ†é›†å¤§çº² -> åˆ†é•œè„šæœ¬ -> å®Œæ•´å‰§æœ¬
"""

import json
import logging
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Optional

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from unimem.adapters.script_adapter import ScriptAdapter

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def extract_json_from_text(text: str) -> Optional[Dict[str, Any]]:
    """
    ä»æ–‡æœ¬ä¸­æå– JSONï¼Œæ”¯æŒå¤šç§æ ¼å¼ï¼ˆå¢å¼ºç‰ˆï¼‰
    
    å°è¯•å¤šç§æ–¹æ³•ï¼š
    1. æŸ¥æ‰¾ { ... } å—
    2. ç§»é™¤ markdown ä»£ç å—æ ‡è®°
    3. ä¿®å¤å¸¸è§çš„ JSON æ ¼å¼é—®é¢˜
    4. å°è¯•éƒ¨åˆ†æå–ï¼ˆå³ä½¿éƒ¨åˆ†æŸåï¼‰
    """
    # æ–¹æ³•1: æŸ¥æ‰¾ markdown ä»£ç å—
    if "```json" in text:
        json_start = text.find("```json") + 7
        json_end = text.find("```", json_start)
        if json_end > json_start:
            text = text[json_start:json_end].strip()
    elif "```" in text:
        json_start = text.find("```") + 3
        json_end = text.find("```", json_start)
        if json_end > json_start:
            text = text[json_start:json_end].strip()
    
    # æ–¹æ³•2: æŸ¥æ‰¾ç¬¬ä¸€ä¸ª { åˆ°æœ€åä¸€ä¸ª } ä¹‹é—´çš„å†…å®¹
    first_brace = text.find('{')
    last_brace = text.rfind('}')
    if first_brace >= 0 and last_brace > first_brace:
        text = text[first_brace:last_brace + 1]
    
    # æ–¹æ³•3: ä¿®å¤å¸¸è§çš„ JSON é—®é¢˜
    try:
        # ç§»é™¤æ§åˆ¶å­—ç¬¦ï¼ˆé™¤äº†æ¢è¡Œå’Œåˆ¶è¡¨ç¬¦ï¼‰
        text = re.sub(r'[\x00-\x08\x0b-\x0c\x0e-\x1f]', '', text)
        # ä¿®å¤å•å¼•å·ä¸ºåŒå¼•å·ï¼ˆåœ¨é”®åå’Œå­—ç¬¦ä¸²å€¼ä¸­ï¼‰
        text = re.sub(r"'(\w+)':", r'"\1":', text)
        text = re.sub(r":\s*'([^']*)'", r': "\1"', text)
        # ä¿®å¤å°¾éšé€—å·
        text = re.sub(r',\s*}', '}', text)
        text = re.sub(r',\s*]', ']', text)
        # ä¿®å¤ç¼ºå¤±çš„å¼•å·ï¼ˆåœ¨é”®åä¸­ï¼‰
        text = re.sub(r'(\w+):', r'"\1":', text)
        # ä¿®å¤æœªè½¬ä¹‰çš„æ¢è¡Œç¬¦
        text = text.replace('\n', '\\n').replace('\r', '\\r')
        
        return json.loads(text)
    except json.JSONDecodeError as e:
        # æ–¹æ³•4: å°è¯•éƒ¨åˆ†æå– - æ‰¾åˆ° episode_outlines æ•°ç»„
        try:
            # æŸ¥æ‰¾ "episode_outlines" æ•°ç»„
            outlines_start = text.find('"episode_outlines"')
            if outlines_start >= 0:
                array_start = text.find('[', outlines_start)
                if array_start >= 0:
                    # å°è¯•æå–æ•°ç»„å†…å®¹
                    bracket_count = 0
                    array_end = array_start
                    for i in range(array_start, len(text)):
                        if text[i] == '[':
                            bracket_count += 1
                        elif text[i] == ']':
                            bracket_count -= 1
                            if bracket_count == 0:
                                array_end = i + 1
                                break
                    
                    if array_end > array_start:
                        array_text = text[array_start:array_end]
                        # å°è¯•è§£ææ•°ç»„
                        outlines = json.loads(array_text)
                        return {"episode_outlines": outlines}
        except:
            pass
        
        # æ–¹æ³•5: å°è¯•é€è¡Œä¿®å¤
        try:
            lines = text.split('\n')
            fixed_lines = []
            for line in lines:
                # è·³è¿‡æ³¨é‡Šè¡Œ
                if line.strip().startswith('//') or line.strip().startswith('#'):
                    continue
                # ä¿®å¤å¸¸è§çš„è¡Œå†…é—®é¢˜
                line = re.sub(r',\s*$', '', line)  # ç§»é™¤è¡Œå°¾é€—å·
                fixed_lines.append(line)
            fixed_text = '\n'.join(fixed_lines)
            return json.loads(fixed_text)
        except:
            pass
        
        logger.debug(f"JSON extraction failed after all attempts: {e}")
        return None
    except Exception as e:
        logger.debug(f"JSON extraction failed: {e}")
        return None


def generate_script_outline(adapter: ScriptAdapter, theme: str = "éƒ½å¸‚æ‚¬ç–‘") -> str:
    """ç”Ÿæˆæ•…äº‹å¤§çº²"""
    logger.info("="*60)
    logger.info("æ­¥éª¤1: ç”Ÿæˆæ•…äº‹å¤§çº²")
    logger.info("="*60)
    
    prompt = f"""è¯·åˆ›ä½œä¸€ä¸ª{theme}é¢˜æçš„50é›†çŸ­å‰§æ•…äº‹å¤§çº²ã€‚

è¦æ±‚ï¼š
1. ç”œå® ä¸»é¢˜ï¼šè¦æœ‰ç”œèœœçš„æ‹çˆ±å…ƒç´ ï¼Œç”·å¥³ä¸»è§’çš„äº’åŠ¨è¦æœ‰ç”œåº¦
2. é€‚åˆçŸ­å‰§çš„å¿«èŠ‚å¥å™äº‹
3. æ¯é›†3-5åˆ†é’Ÿï¼Œ50é›†æ€»æ—¶é•¿çº¦150-250åˆ†é’Ÿ
4. è¦æœ‰æ˜ç¡®çš„ä¸»çº¿å’Œå‰¯çº¿ï¼ˆå¯ä»¥æ˜¯è¯¯ä¼šã€è¿½æ±‚ã€å® æººç­‰ï¼‰
5. äººç‰©å…³ç³»è¦æœ‰ç”œå® æ„Ÿï¼Œç”·ä¸»è¦æœ‰å® æººå±æ€§ï¼Œå¥³ä¸»è¦æœ‰å¯çˆ±æˆ–ç‹¬ç«‹ç‰¹è´¨
6. é€‚åˆçŸ­è§†é¢‘å¹³å°çš„è§‚çœ‹ä¹ æƒ¯ï¼Œæ¯é›†è¦æœ‰ç”œå® äº®ç‚¹
7. å¯ä»¥åŒ…å«ï¼šéœ¸é“æ€»è£ã€é’æ¢…ç«¹é©¬ã€å¥‘çº¦å©šå§»ã€æ ¡å›­æ‹çˆ±ç­‰ç”œå® å…ƒç´ 

è¯·ä»¥ JSON æ ¼å¼è¿”å›ç»“æœï¼š
{{
    "title": "çŸ­å‰§æ ‡é¢˜",
    "genre": "é¢˜æç±»å‹",
    "theme": "ä¸»é¢˜",
    "main_storyline": "ä¸»è¦æ•…äº‹çº¿",
    "main_characters": [
        {{
            "name": "è§’è‰²å",
            "role": "è§’è‰²å®šä½",
            "characteristics": "è§’è‰²ç‰¹ç‚¹"
        }}
    ],
    "conflicts": ["å†²çª1", "å†²çª2", ...],
    "plot_structure": {{
        "act1": "ç¬¬ä¸€å¹•ï¼šå¼€ç«¯ï¼ˆ1-15é›†ï¼‰",
        "act2": "ç¬¬äºŒå¹•ï¼šå‘å±•ï¼ˆ16-35é›†ï¼‰",
        "act3": "ç¬¬ä¸‰å¹•ï¼šé«˜æ½®ä¸ç»“å±€ï¼ˆ36-50é›†ï¼‰"
    }},
    "key_turning_points": ["è½¬æŠ˜ç‚¹1", "è½¬æŠ˜ç‚¹2", ...],
    "target_audience": "ç›®æ ‡å—ä¼—"
}}"""
    
    try:
        from unimem.chat import ark_deepseek_v3_2
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ­å‰§å‰§æœ¬åˆ›ä½œåŠ©æ‰‹ï¼Œæ“…é•¿åˆ›ä½œé€‚åˆçŸ­è§†é¢‘å¹³å°çš„çŸ­å‰§æ•…äº‹å¤§çº²ã€‚è¯·å§‹ç»ˆä»¥æœ‰æ•ˆçš„ JSON æ ¼å¼è¿”å›ç»“æœã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        _, response_text = ark_deepseek_v3_2(messages, max_new_tokens=2048)
        result = adapter._parse_json_response(response_text)
        
        if result:
            logger.info("âœ… æ•…äº‹å¤§çº²ç”Ÿæˆå®Œæˆ")
            return json.dumps(result, ensure_ascii=False, indent=2)
        else:
            logger.warning("å¤§çº²ç”Ÿæˆå¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨æå– JSON...")
            # å°è¯•æ›´å®½æ¾çš„ JSON æå–
            result = extract_json_from_text(response_text)
            if result:
                logger.info("âœ… é€šè¿‡æ‰‹åŠ¨æå–æˆåŠŸè§£æå¤§çº²")
                return json.dumps(result, ensure_ascii=False, indent=2)
            
            logger.warning("ä½¿ç”¨ç”œå® ä¸»é¢˜é»˜è®¤å¤§çº²")
            return json.dumps({
                "title": "ç”œå® çŸ­å‰§",
                "genre": "ç”œå® ",
                "theme": "ç”œèœœæ‹çˆ±",
                "main_storyline": "ä¸€ä¸ªæ™®é€šå¥³å­©ä¸éœ¸é“æ€»è£çš„ç”œèœœæ‹çˆ±æ•…äº‹ï¼Œä»è¯¯ä¼šåˆ°ç›¸çŸ¥ï¼Œä»ç›¸çŸ¥åˆ°ç›¸çˆ±ï¼Œæœ€ç»ˆæ”¶è·å¹¸ç¦ã€‚",
                "main_characters": [
                    {
                        "name": "å¥³ä¸»è§’",
                        "role": "æ™®é€šå¥³å­©ï¼Œå–„è‰¯ç‹¬ç«‹",
                        "characteristics": "å¯çˆ±ã€åšå¼ºã€æœ‰è‡ªå·±çš„æ¢¦æƒ³"
                    },
                    {
                        "name": "ç”·ä¸»è§’",
                        "role": "éœ¸é“æ€»è£",
                        "characteristics": "é«˜å†·å¤–è¡¨ä¸‹éšè—æ¸©æŸ”ï¼Œå¯¹å¥³ä¸»è§’å® æººæœ‰åŠ "
                    }
                ],
                "conflicts": ["èº«ä»½å·®è·", "è¯¯ä¼š", "ç¬¬ä¸‰è€…ä»‹å…¥"],
                "plot_structure": {
                    "act1": "ç¬¬ä¸€å¹•ï¼šç›¸é‡ä¸è¯¯ä¼šï¼ˆ1-15é›†ï¼‰",
                    "act2": "ç¬¬äºŒå¹•ï¼šç›¸çŸ¥ä¸å¿ƒåŠ¨ï¼ˆ16-35é›†ï¼‰",
                    "act3": "ç¬¬ä¸‰å¹•ï¼šç›¸çˆ±ä¸å¹¸ç¦ï¼ˆ36-50é›†ï¼‰"
                },
                "key_turning_points": ["åˆæ¬¡ç›¸é‡", "è¯¯ä¼šè§£é™¤", "è¡¨ç™½", "åœ¨ä¸€èµ·"],
                "target_audience": "18-35å²å¥³æ€§è§‚ä¼—"
            }, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.error(f"ç”Ÿæˆæ•…äº‹å¤§çº²å¤±è´¥: {e}")
        return ""


def generate_episode_outlines(adapter: ScriptAdapter, outline: Dict[str, Any], num_episodes: int = 50) -> List[Dict[str, Any]]:
    """
    ç”Ÿæˆåˆ†é›†å¤§çº²ï¼ˆå¢å¼ºç‰ˆï¼šå¸¦é‡è¯•æœºåˆ¶å’Œå®Œæ•´æ€§æ£€æŸ¥ï¼‰
    """
    logger.info("="*60)
    logger.info(f"æ­¥éª¤2: ç”Ÿæˆ{num_episodes}é›†åˆ†é›†å¤§çº²")
    logger.info("="*60)
    
    # å°†å¤§çº²è½¬æ¢ä¸ºæ–‡æœ¬
    outline_text = f"""
æ ‡é¢˜ï¼š{outline.get('title', '')}
é¢˜æï¼š{outline.get('genre', '')}
ä¸»é¢˜ï¼š{outline.get('theme', '')}
ä¸»è¦æ•…äº‹çº¿ï¼š{outline.get('main_storyline', '')}
ä¸»è¦è§’è‰²ï¼š{json.dumps(outline.get('main_characters', [])[:5], ensure_ascii=False)}
æ ¸å¿ƒå†²çªï¼š{json.dumps(outline.get('conflicts', [])[:5], ensure_ascii=False)}
å‰§æƒ…ç»“æ„ï¼š
{outline.get('plot_structure', {}).get('act1', '')}
{outline.get('plot_structure', {}).get('act2', '')}
{outline.get('plot_structure', {}).get('act3', '')}
å…³é”®è½¬æŠ˜ç‚¹ï¼š{json.dumps(outline.get('key_turning_points', [])[:5], ensure_ascii=False)}
"""
    
    # åˆ†æ‰¹ç”Ÿæˆï¼ˆæ¯æ¬¡ç”Ÿæˆ5é›†ï¼Œé™ä½å‡ºé”™æ¦‚ç‡ï¼‰
    all_outlines = []
    batch_size = 5
    max_retries = 3  # æ¯æ‰¹æ¬¡æœ€å¤šé‡è¯•3æ¬¡
    failed_batches = []  # è®°å½•å¤±è´¥çš„æ‰¹æ¬¡
    
    for batch_start in range(0, num_episodes, batch_size):
        batch_end = min(batch_start + batch_size, num_episodes)
        batch_num = batch_start // batch_size + 1
        total_batches = (num_episodes + batch_size - 1) // batch_size
        
        logger.info(f"\nç”Ÿæˆç¬¬ {batch_start+1}-{batch_end} é›†å¤§çº²ï¼ˆæ‰¹æ¬¡ {batch_num}/{total_batches}ï¼‰...")
        
        prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹æ•…äº‹å¤§çº²ï¼Œç”Ÿæˆç¬¬{batch_start+1}åˆ°ç¬¬{batch_end}é›†çš„åˆ†é›†å¤§çº²ã€‚

æ•…äº‹å¤§çº²ï¼š
{outline_text}

è¦æ±‚ï¼š
1. æ¯é›†è¦æœ‰å®Œæ•´çš„æƒ…èŠ‚å•å…ƒ
2. ä¿æŒèŠ‚å¥ç´§å‡‘ï¼Œæ¯é›†æœ‰é«˜æ½®ç‚¹
3. æ¯é›†æ—¶é•¿æ§åˆ¶åœ¨3-5åˆ†é’Ÿ
4. åˆ†é›†ä¹‹é—´è¦æœ‰è¿è´¯æ€§å’Œæ‚¬å¿µ
5. ç¬¬{batch_start+1}é›†è¦å¸å¼•è§‚ä¼—ï¼Œç¬¬{batch_end}é›†è¦æœ‰æ‚¬å¿µ
6. **é‡è¦ï¼šå¿…é¡»ç”Ÿæˆå®Œæ•´çš„ {batch_end - batch_start} é›†ï¼Œæ¯é›†éƒ½è¦æœ‰ episode_numã€titleã€summaryã€key_scenesã€main_conflictã€climaxã€hookã€ending_hook å­—æ®µ**

è¯·ä»¥ JSON æ ¼å¼è¿”å›ç»“æœï¼ˆç¡®ä¿æ ¼å¼æ­£ç¡®ï¼Œä¸è¦æœ‰è¯­æ³•é”™è¯¯ï¼‰ï¼š
{{
    "episode_outlines": [
        {{
            "episode_num": {batch_start+1},
            "title": "åˆ†é›†æ ‡é¢˜",
            "summary": "åˆ†é›†æ‘˜è¦ï¼ˆ100-150å­—ï¼‰",
            "key_scenes": ["åœºæ™¯1", "åœºæ™¯2", "åœºæ™¯3"],
            "main_conflict": "æ ¸å¿ƒå†²çª",
            "climax": "é«˜æ½®ç‚¹",
            "hook": "å¸å¼•è§‚ä¼—çš„é’©å­",
            "ending_hook": "ç»“å°¾æ‚¬å¿µ"
        }},
        {{
            "episode_num": {batch_start+2},
            ...
        }}
    ]
}}"""
        
        # é‡è¯•æœºåˆ¶
        batch_success = False
        for attempt in range(max_retries):
            try:
                from unimem.chat import ark_deepseek_v3_2
                messages = [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ­å‰§å‰§æœ¬åˆ›ä½œåŠ©æ‰‹ï¼Œæ“…é•¿åˆ›ä½œåˆ†é›†å¤§çº²ã€‚è¯·å§‹ç»ˆä»¥æœ‰æ•ˆçš„ã€å®Œæ•´çš„ JSON æ ¼å¼è¿”å›ç»“æœï¼Œç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½å­˜åœ¨ã€‚"},
                    {"role": "user", "content": prompt}
                ]
                
                _, response_text = ark_deepseek_v3_2(messages, max_new_tokens=4096)
                
                # ä¿å­˜åŸå§‹å“åº”ï¼ˆç”¨äºè°ƒè¯•ï¼‰
                if attempt == 0:
                    debug_file = Path(__file__).parent.parent.parent / 'data' / f'debug_batch_{batch_start+1}_{batch_end}.txt'
                    with open(debug_file, 'w', encoding='utf-8') as f:
                        f.write(response_text)
                
                result = adapter._parse_json_response(response_text)
                
                # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨æå–
                if not result:
                    if attempt < max_retries - 1:
                        logger.warning(f"ç¬¬ {batch_start+1}-{batch_end} é›† JSON è§£æå¤±è´¥ï¼ˆå°è¯• {attempt+1}/{max_retries}ï¼‰ï¼Œå°è¯•æ‰‹åŠ¨æå–...")
                    else:
                        logger.warning(f"ç¬¬ {batch_start+1}-{batch_end} é›† JSON è§£æå¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨æå–...")
                    result = extract_json_from_text(response_text)
                
                if result and "episode_outlines" in result:
                    batch_outlines = result["episode_outlines"]
                    
                    # éªŒè¯æ‰¹æ¬¡å®Œæ•´æ€§
                    expected_episodes = set(range(batch_start + 1, batch_end + 1))
                    actual_episodes = set(ep.get('episode_num', 0) for ep in batch_outlines)
                    
                    if len(batch_outlines) == batch_end - batch_start and expected_episodes == actual_episodes:
                        all_outlines.extend(batch_outlines)
                        logger.info(f"âœ… ç¬¬ {batch_start+1}-{batch_end} é›†å¤§çº²ç”Ÿæˆå®Œæˆï¼ˆ{len(batch_outlines)} é›†ï¼‰")
                        batch_success = True
                        break
                    else:
                        missing = expected_episodes - actual_episodes
                        logger.warning(f"âš ï¸ æ‰¹æ¬¡ä¸å®Œæ•´ï¼šæœŸæœ› {len(expected_episodes)} é›†ï¼Œå®é™… {len(batch_outlines)} é›†ï¼Œç¼ºå¤±: {missing}")
                        if attempt < max_retries - 1:
                            logger.info(f"  é‡è¯•ä¸­... ({attempt+2}/{max_retries})")
                            import time
                            time.sleep(2)
                            continue
                else:
                    if attempt < max_retries - 1:
                        logger.warning(f"ç¬¬ {batch_start+1}-{batch_end} é›†å¤§çº²ç”Ÿæˆå¤±è´¥ï¼ˆå°è¯• {attempt+1}/{max_retries}ï¼‰ï¼Œå“åº”æ–‡æœ¬: {response_text[:200]}...")
                        import time
                        time.sleep(2)
                        continue
                    else:
                        logger.error(f"ç¬¬ {batch_start+1}-{batch_end} é›†å¤§çº²ç”Ÿæˆå¤±è´¥ï¼Œå“åº”æ–‡æœ¬: {response_text[:200]}...")
                
            except Exception as e:
                logger.error(f"ç”Ÿæˆç¬¬ {batch_start+1}-{batch_end} é›†å¤§çº²å¤±è´¥ï¼ˆå°è¯• {attempt+1}/{max_retries}ï¼‰: {e}")
                if attempt < max_retries - 1:
                    import time
                    time.sleep(2)
                    continue
        
        if not batch_success:
            failed_batches.append((batch_start + 1, batch_end))
            logger.error(f"âŒ ç¬¬ {batch_start+1}-{batch_end} é›†å¤§çº²ç”Ÿæˆå¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡")
        
        # æ·»åŠ å»¶è¿Ÿé¿å… API é™æµ
        import time
        if batch_end < num_episodes:
            time.sleep(2)
    
    # å®Œæ•´æ€§æ£€æŸ¥å’Œè¡¥ç”Ÿæˆ
    logger.info(f"\nğŸ“Š å®Œæ•´æ€§æ£€æŸ¥ï¼šå·²ç”Ÿæˆ {len(all_outlines)}/{num_episodes} é›†")
    
    if len(all_outlines) < num_episodes:
        missing_episodes = check_and_fill_missing_outlines(
            adapter, outline, all_outlines, num_episodes, outline_text
        )
        all_outlines.extend(missing_episodes)
        all_outlines.sort(key=lambda x: x.get('episode_num', 0))
    
    logger.info(f"\nâœ… æ‰€æœ‰åˆ†é›†å¤§çº²ç”Ÿæˆå®Œæˆï¼Œå…± {len(all_outlines)} é›†")
    
    # æœ€ç»ˆéªŒè¯
    final_check = verify_outlines_completeness(all_outlines, num_episodes)
    if not final_check:
        logger.error(f"âŒ å®Œæ•´æ€§éªŒè¯å¤±è´¥ï¼šä»æœ‰ç¼ºå¤±é›†æ•°")
    else:
        logger.info(f"âœ… å®Œæ•´æ€§éªŒè¯é€šè¿‡ï¼šæ‰€æœ‰ {num_episodes} é›†å‡å·²ç”Ÿæˆ")
    
    return all_outlines


def check_and_fill_missing_outlines(adapter: ScriptAdapter, outline: Dict[str, Any], 
                                   existing_outlines: List[Dict[str, Any]], 
                                   num_episodes: int, outline_text: str) -> List[Dict[str, Any]]:
    """
    æ£€æŸ¥å¹¶è¡¥ç”Ÿæˆç¼ºå¤±çš„åˆ†é›†å¤§çº²
    """
    expected = set(range(1, num_episodes + 1))
    actual = set(ep.get('episode_num', 0) for ep in existing_outlines)
    missing = sorted(list(expected - actual))
    
    if not missing:
        return []
    
    logger.warning(f"âš ï¸ å‘ç°ç¼ºå¤±é›†æ•°: {missing}ï¼Œå¼€å§‹è¡¥ç”Ÿæˆ...")
    
    filled_outlines = []
    
    # å°†ç¼ºå¤±çš„é›†æ•°åˆ†ç»„ï¼ˆæ¯ç»„æœ€å¤š5é›†ï¼‰
    batch_size = 5
    for i in range(0, len(missing), batch_size):
        missing_batch = missing[i:i+batch_size]
        batch_start = missing_batch[0]
        batch_end = missing_batch[-1]
        
        logger.info(f"è¡¥ç”Ÿæˆç¬¬ {batch_start}-{batch_end} é›†å¤§çº²...")
        
        prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹æ•…äº‹å¤§çº²ï¼Œç”Ÿæˆç¬¬{batch_start}åˆ°ç¬¬{batch_end}é›†çš„åˆ†é›†å¤§çº²ã€‚

æ•…äº‹å¤§çº²ï¼š
{outline_text}

è¦æ±‚ï¼š
1. æ¯é›†è¦æœ‰å®Œæ•´çš„æƒ…èŠ‚å•å…ƒ
2. ä¿æŒèŠ‚å¥ç´§å‡‘ï¼Œæ¯é›†æœ‰é«˜æ½®ç‚¹
3. æ¯é›†æ—¶é•¿æ§åˆ¶åœ¨3-5åˆ†é’Ÿ
4. åˆ†é›†ä¹‹é—´è¦æœ‰è¿è´¯æ€§å’Œæ‚¬å¿µ
5. **é‡è¦ï¼šå¿…é¡»ç”Ÿæˆå®Œæ•´çš„ {len(missing_batch)} é›†ï¼Œæ¯é›†éƒ½è¦æœ‰ episode_numã€titleã€summaryã€key_scenesã€main_conflictã€climaxã€hookã€ending_hook å­—æ®µ**

è¯·ä»¥ JSON æ ¼å¼è¿”å›ç»“æœï¼š
{{
    "episode_outlines": [
        {{
            "episode_num": {batch_start},
            "title": "åˆ†é›†æ ‡é¢˜",
            "summary": "åˆ†é›†æ‘˜è¦ï¼ˆ100-150å­—ï¼‰",
            "key_scenes": ["åœºæ™¯1", "åœºæ™¯2", "åœºæ™¯3"],
            "main_conflict": "æ ¸å¿ƒå†²çª",
            "climax": "é«˜æ½®ç‚¹",
            "hook": "å¸å¼•è§‚ä¼—çš„é’©å­",
            "ending_hook": "ç»“å°¾æ‚¬å¿µ"
        }},
        ...
    ]
}}"""
        
        max_retries = 3
        for attempt in range(max_retries):
            try:
                from unimem.chat import ark_deepseek_v3_2
                messages = [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ­å‰§å‰§æœ¬åˆ›ä½œåŠ©æ‰‹ï¼Œæ“…é•¿åˆ›ä½œåˆ†é›†å¤§çº²ã€‚è¯·å§‹ç»ˆä»¥æœ‰æ•ˆçš„ã€å®Œæ•´çš„ JSON æ ¼å¼è¿”å›ç»“æœã€‚"},
                    {"role": "user", "content": prompt}
                ]
                
                _, response_text = ark_deepseek_v3_2(messages, max_new_tokens=4096)
                result = adapter._parse_json_response(response_text)
                
                if not result:
                    result = extract_json_from_text(response_text)
                
                if result and "episode_outlines" in result:
                    batch_outlines = result["episode_outlines"]
                    filled_outlines.extend(batch_outlines)
                    logger.info(f"âœ… è¡¥ç”Ÿæˆå®Œæˆï¼šç¬¬ {batch_start}-{batch_end} é›†ï¼ˆ{len(batch_outlines)} é›†ï¼‰")
                    break
                else:
                    if attempt < max_retries - 1:
                        logger.warning(f"è¡¥ç”Ÿæˆå¤±è´¥ï¼ˆå°è¯• {attempt+1}/{max_retries}ï¼‰ï¼Œé‡è¯•ä¸­...")
                        import time
                        time.sleep(2)
            except Exception as e:
                logger.error(f"è¡¥ç”Ÿæˆç¬¬ {batch_start}-{batch_end} é›†å¤±è´¥ï¼ˆå°è¯• {attempt+1}/{max_retries}ï¼‰: {e}")
                if attempt < max_retries - 1:
                    import time
                    time.sleep(2)
        
        import time
        time.sleep(2)
    
    return filled_outlines


def verify_outlines_completeness(outlines: List[Dict[str, Any]], num_episodes: int) -> bool:
    """
    éªŒè¯åˆ†é›†å¤§çº²çš„å®Œæ•´æ€§
    """
    expected = set(range(1, num_episodes + 1))
    actual = set(ep.get('episode_num', 0) for ep in outlines)
    missing = sorted(list(expected - actual))
    
    if missing:
        logger.error(f"âŒ å®Œæ•´æ€§éªŒè¯å¤±è´¥ï¼šç¼ºå¤±é›†æ•° {missing}")
        return False
    
    logger.info(f"âœ… å®Œæ•´æ€§éªŒè¯é€šè¿‡ï¼šæ‰€æœ‰ {num_episodes} é›†å‡å·²ç”Ÿæˆ")
    return True


def validate_generated_script(script_content: str, expected_outline: Dict[str, Any], outline: Dict[str, Any], adapter: ScriptAdapter) -> dict:
    """
    åå‘ç»“æ„åŒ–æ ¡éªŒï¼šå¯¹ç”Ÿæˆçš„å‰§æœ¬è¿›è¡Œç»“æ„åŒ–åˆ†æï¼Œå¹¶ä¸é¢„æœŸåˆ†é›†å¤§çº²å¯¹æ¯”
    
    Returns:
        {
            'accuracy_score': float,  # å‡†ç¡®åº¦è¯„åˆ† 0-1
            'validation_result': dict,  # è¯¦ç»†æ ¡éªŒç»“æœ
            'issues': list,  # å‘ç°çš„é—®é¢˜
            'suggestions': list  # ä¼˜åŒ–å»ºè®®
        }
    """
    if not adapter.is_available():
        return {'accuracy_score': 0.5, 'validation_result': {}, 'issues': [], 'suggestions': []}
    
    try:
        # 1. å¯¹ç”Ÿæˆå‰§æœ¬è¿›è¡Œåå‘ç»“æ„åŒ–åˆ†æ
        logger.info("  è¿›è¡Œåå‘ç»“æ„åŒ–åˆ†æ...")
        generated_analysis = adapter._analyze_script_content(
            script_content[:2000]  # é™åˆ¶é•¿åº¦
        )
        
        # 2. å¯¹é¢„æœŸåˆ†é›†å¤§çº²è¿›è¡Œç»“æ„åŒ–åˆ†æ
        expected_summary = expected_outline.get('summary', '')
        expected_analysis = adapter._analyze_script_content(
            expected_summary
        )
        
        # 3. å¯¹æ¯”åˆ†æ
        logger.info("  è¿›è¡Œå¯¹æ¯”æ ¡éªŒ...")
        from unimem.chat import ark_deepseek_v3_2
        
        comparison_prompt = f"""è¯·å¯¹æ¯”ä»¥ä¸‹ä¸¤æ®µå†…å®¹çš„ç»“æ„åŒ–åˆ†æç»“æœï¼Œè¯„ä¼°ç”Ÿæˆå‰§æœ¬æ˜¯å¦ç¬¦åˆé¢„æœŸè¦æ±‚ã€‚

ã€é¢„æœŸåˆ†é›†å¤§çº²çš„ç»“æ„åŒ–åˆ†æã€‘
å…³é”®è¯: {', '.join(expected_analysis.get('keywords', [])[:10])}
ä¸Šä¸‹æ–‡: {expected_analysis.get('context', '')}
å‰§æœ¬ç»´åº¦: {json.dumps(expected_analysis.get('script_dimensions', {}), ensure_ascii=False)}

ã€ç”Ÿæˆå‰§æœ¬çš„ç»“æ„åŒ–åˆ†æã€‘
å…³é”®è¯: {', '.join(generated_analysis.get('keywords', [])[:10])}
ä¸Šä¸‹æ–‡: {generated_analysis.get('context', '')}
å‰§æœ¬ç»´åº¦: {json.dumps(generated_analysis.get('script_dimensions', {}), ensure_ascii=False)}

ã€åˆ›ä½œè®¾å®šè¦æ±‚ã€‘
- ä½œå“ç±»å‹: {outline.get('genre', '')}
- ä¸»è¦äººç‰©: {json.dumps([c.get('name') for c in outline.get('main_characters', [])[:3]], ensure_ascii=False)}
- ä¸»é¢˜: {outline.get('theme', '')[:200]}

ã€é¢„æœŸåˆ†é›†å¤§çº²è¦æ±‚ã€‘
- æ ‡é¢˜: {expected_outline.get('title', '')}
- æ ¸å¿ƒå†²çª: {expected_outline.get('main_conflict', '')}
- å…³é”®åœºæ™¯: {json.dumps(expected_outline.get('key_scenes', [])[:5], ensure_ascii=False)}
- é«˜æ½®ç‚¹: {expected_outline.get('climax', '')}

è¯·è¯„ä¼°ï¼š
1. ç”Ÿæˆå‰§æœ¬æ˜¯å¦æ¶µç›–äº†é¢„æœŸåˆ†é›†å¤§çº²çš„æ ¸å¿ƒæƒ…èŠ‚ï¼Ÿ
2. ç”Ÿæˆå‰§æœ¬æ˜¯å¦ç¬¦åˆåˆ›ä½œè®¾å®šï¼ˆäººç‰©ã€ä¸–ç•Œè§‚ã€é£æ ¼ï¼‰ï¼Ÿ
3. æ˜¯å¦å­˜åœ¨æ˜æ˜¾åå·®æˆ–é—æ¼ï¼Ÿ

è¯·ä»¥ JSON æ ¼å¼è¿”å›ç»“æœï¼š
{{
    "accuracy_score": 0.0-1.0,  // å‡†ç¡®åº¦è¯„åˆ†
    "coverage": {{
        "plot_coverage": 0.0-1.0,  // æƒ…èŠ‚è¦†ç›–åº¦
        "character_consistency": 0.0-1.0,  // äººç‰©ä¸€è‡´æ€§
        "setting_consistency": 0.0-1.0,  // è®¾å®šä¸€è‡´æ€§
        "style_consistency": 0.0-1.0  // é£æ ¼ä¸€è‡´æ€§
    }},
    "issues": [
        "é—®é¢˜1æè¿°",
        "é—®é¢˜2æè¿°"
    ],
    "suggestions": [
        "ä¼˜åŒ–å»ºè®®1",
        "ä¼˜åŒ–å»ºè®®2"
    ]
}}"""
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹è´¨é‡è¯„ä¼°åŠ©æ‰‹ï¼Œæ“…é•¿å¯¹æ¯”åˆ†ææ–‡æœ¬å†…å®¹æ˜¯å¦ç¬¦åˆé¢„æœŸè¦æ±‚ã€‚è¯·å§‹ç»ˆä»¥æœ‰æ•ˆçš„ JSON æ ¼å¼è¿”å›ç»“æœã€‚"},
            {"role": "user", "content": comparison_prompt}
        ]
        
        _, response_text = ark_deepseek_v3_2(messages, max_new_tokens=1024)
        validation_result = adapter._parse_json_response(response_text)
        
        if validation_result:
            accuracy_score = validation_result.get('accuracy_score', 0.5)
            logger.info(f"  âœ… æ ¡éªŒå®Œæˆï¼Œå‡†ç¡®åº¦è¯„åˆ†: {accuracy_score:.2f}")
            return {
                'accuracy_score': accuracy_score,
                'validation_result': validation_result,
                'issues': validation_result.get('issues', []),
                'suggestions': validation_result.get('suggestions', []),
                'coverage': validation_result.get('coverage', {})
            }
        else:
            logger.warning("  æ ¡éªŒç»“æœè§£æå¤±è´¥")
            return {'accuracy_score': 0.5, 'validation_result': {}, 'issues': [], 'suggestions': []}
            
    except Exception as e:
        logger.error(f"  æ ¡éªŒè¿‡ç¨‹å‡ºé”™: {e}")
        return {'accuracy_score': 0.5, 'validation_result': {}, 'issues': [], 'suggestions': []}


def build_enhanced_prompt_with_feedback(original_prompt: str, validation_result: dict, attempt: int) -> str:
    """
    æ ¹æ®æ ¡éªŒåé¦ˆæ„å»ºå¢å¼ºçš„ promptï¼ˆç”¨äºå‰§æœ¬ç”Ÿæˆï¼‰
    
    å°† issues å’Œ suggestions è½¬åŒ–ä¸ºå…·ä½“çš„ç”ŸæˆæŒ‡å¯¼
    """
    issues = validation_result.get('issues', [])
    suggestions = validation_result.get('suggestions', [])
    coverage = validation_result.get('coverage', {})
    
    feedback_section = "\n\nã€é‡è¦ï¼šæ ¹æ®ä¸Šä¸€ç‰ˆç”Ÿæˆç»“æœçš„åé¦ˆï¼Œè¯·ç‰¹åˆ«æ³¨æ„ä»¥ä¸‹è¦æ±‚ã€‘\n"
    
    # 1. æ˜ç¡®æŒ‡å‡ºéœ€è¦é¿å…çš„é—®é¢˜
    if issues:
        feedback_section += "\nã€éœ€è¦é¿å…çš„é—®é¢˜ã€‘\n"
        for i, issue in enumerate(issues[:5], 1):
            feedback_section += f"{i}. {issue}\n"
        feedback_section += "\nè¯·ç¡®ä¿ç”Ÿæˆçš„å†…å®¹é¿å…ä¸Šè¿°é—®é¢˜ã€‚\n"
    
    # 2. æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®
    if suggestions:
        feedback_section += "\nã€æ”¹è¿›æ–¹å‘ã€‘\n"
        for i, suggestion in enumerate(suggestions[:5], 1):
            feedback_section += f"{i}. {suggestion}\n"
        feedback_section += "\nè¯·åœ¨ç”Ÿæˆæ—¶å……åˆ†è€ƒè™‘å¹¶ä½“ç°ä¸Šè¿°æ”¹è¿›å»ºè®®ã€‚\n"
    
    # 3. æ ¹æ®å„ç»´åº¦è¯„åˆ†æä¾›é’ˆå¯¹æ€§æŒ‡å¯¼
    if coverage:
        feedback_section += "\nã€å„ç»´åº¦è¦æ±‚ã€‘\n"
        if coverage.get('plot_coverage', 1.0) < 0.8:
            feedback_section += "- è¯·ç¡®ä¿å®Œæ•´æ¶µç›–é¢„æœŸåˆ†é›†å¤§çº²çš„æ ¸å¿ƒæƒ…èŠ‚ï¼Œä¸è¦é—æ¼é‡è¦æƒ…èŠ‚ç‚¹\n"
        if coverage.get('character_consistency', 1.0) < 0.8:
            feedback_section += "- è¯·ä¸¥æ ¼éµå¾ªåˆ›ä½œè®¾å®šä¸­çš„äººç‰©æ€§æ ¼å’Œè¡Œä¸ºç‰¹å¾\n"
        if coverage.get('setting_consistency', 1.0) < 0.8:
            feedback_section += "- è¯·ç¡®ä¿ä¸–ç•Œè§‚ã€èƒŒæ™¯è®¾å®šä¸åˆ›ä½œè®¾å®šå®Œå…¨ä¸€è‡´\n"
        if coverage.get('style_consistency', 1.0) < 0.8:
            feedback_section += "- è¯·ä¿æŒä¸åˆ›ä½œè®¾å®šè¦æ±‚çš„å‰§æœ¬é£æ ¼ä¸€è‡´\n"
    
    feedback_section += f"\nè¿™æ˜¯ç¬¬ {attempt} æ¬¡ç”Ÿæˆå°è¯•ï¼Œè¯·åŠ¡å¿…è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œç”Ÿæˆæ›´ç¬¦åˆè¦æ±‚çš„å†…å®¹ã€‚\n"
    
    return original_prompt + feedback_section


def generate_full_script(adapter: ScriptAdapter, episode_outline: Dict[str, Any], outline: Dict[str, Any], context_memories: List = None, enable_validation: bool = True, validation_threshold: float = 0.7, max_retries: int = 2) -> tuple:
    """
    ç”Ÿæˆå®Œæ•´å‰§æœ¬ï¼ˆå¸¦ä¸Šä¸‹æ–‡å’Œåå‘ç»“æ„åŒ–æ ¡éªŒï¼‰
    
    Args:
        adapter: é€‚é…å™¨
        episode_outline: åˆ†é›†å¤§çº²
        outline: æ•…äº‹å¤§çº²
        context_memories: ä¸Šä¸‹æ–‡è®°å¿†ï¼ˆå‰å‡ é›†çš„è®°å¿†ï¼‰
        enable_validation: æ˜¯å¦å¯ç”¨æ ¡éªŒ
        validation_threshold: æ ¡éªŒé˜ˆå€¼
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        
    Returns:
        (script_content, validation_result)
    """
    episode_num = episode_outline.get('episode_num', 1)
    logger.info(f"\nç”Ÿæˆç¬¬ {episode_num} é›†å®Œæ•´å‰§æœ¬...")
    
    # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
    context_text = ""
    if context_memories:
        context_text = "\n\nã€å‰é›†ä¸Šä¸‹æ–‡ã€‘\n"
        for mem in context_memories[:3]:  # ä½¿ç”¨æœ€è¿‘3é›†çš„è®°å¿†
            context_text += f"- {mem.content[:200]}\n"
            if mem.metadata and mem.metadata.get("script_dimensions"):
                dims = mem.metadata["script_dimensions"]
                if dims.get("scenes"):
                    context_text += f"  åœºæ™¯: {', '.join(dims['scenes'][:2])}\n"
                if dims.get("characters"):
                    context_text += f"  äººç‰©: {', '.join(dims['characters'][:2])}\n"
    
    # å¦‚æœæœ‰å‰é›†çš„æ ¡éªŒåé¦ˆï¼ŒåŠ å…¥æŒ‡å¯¼
    previous_feedback = ""
    if 'validation_feedback' in outline and outline['validation_feedback']:
        recent_feedback = outline['validation_feedback'][-1]
        if recent_feedback.get('episode') < episode_num:
            previous_feedback = "\n\nã€å‚è€ƒï¼šå‰é›†çš„æ”¹è¿›å»ºè®®ã€‘\n"
            if recent_feedback.get('suggestions'):
                previous_feedback += "ä»¥ä¸‹å»ºè®®æ¥è‡ªå‰é›†çš„æ ¡éªŒåé¦ˆï¼Œè¯·åœ¨ç”Ÿæˆæ—¶å‚è€ƒï¼š\n"
                for i, sug in enumerate(recent_feedback['suggestions'], 1):
                    previous_feedback += f"{i}. {sug}\n"
    
    # å¦‚æœæœ‰å‰é›†çš„è‡ªåŠ¨ä¼˜åŒ–åé¦ˆï¼ŒåŠ å…¥æŒ‡å¯¼
    if 'optimization_feedback' in outline and outline['optimization_feedback']:
        recent_opt_feedback = outline['optimization_feedback'][-1]
        if recent_opt_feedback.get('episode') < episode_num:
            if not previous_feedback:
                previous_feedback = "\n\nã€å‚è€ƒï¼šå‰é›†çš„è‡ªåŠ¨ä¼˜åŒ–å»ºè®®ã€‘\n"
            else:
                previous_feedback += "\nã€å‚è€ƒï¼šå‰é›†çš„è‡ªåŠ¨ä¼˜åŒ–å»ºè®®ã€‘\n"
            
            if recent_opt_feedback.get('suggestions'):
                previous_feedback += "ä»¥ä¸‹å»ºè®®æ¥è‡ªå‰é›†çš„è‡ªåŠ¨ä¼˜åŒ–åˆ†æï¼š\n"
                for i, sug in enumerate(recent_opt_feedback['suggestions'], 1):
                    previous_feedback += f"{i}. {sug}\n"
            
            # æ·»åŠ å‰§æœ¬ç‰¹å®šçš„ä¼˜åŒ–å»ºè®®
            script_specific = recent_opt_feedback.get('script_specific', {})
            if script_specific:
                if script_specific.get('shot_design'):
                    previous_feedback += f"\nåˆ†é•œè®¾è®¡å»ºè®®: {script_specific['shot_design']}\n"
                if script_specific.get('dialogue_style'):
                    previous_feedback += f"å¯¹è¯é£æ ¼å»ºè®®: {script_specific['dialogue_style']}\n"
                if script_specific.get('rhythm_control'):
                    previous_feedback += f"èŠ‚å¥æ§åˆ¶å»ºè®®: {script_specific['rhythm_control']}\n"
    
    # æ„å»ºåˆå§‹ç”Ÿæˆ prompt
    initial_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹åˆ†é›†å¤§çº²å’Œåˆ›ä½œè®¾å®šï¼Œç”Ÿæˆç¬¬{episode_num}é›†çš„å®Œæ•´çŸ­å‰§å‰§æœ¬ã€‚

åˆ›ä½œè®¾å®šï¼š
- ä½œå“ç±»å‹: {outline.get('genre', '')}
- ä¸»é¢˜: {outline.get('theme', '')}
- ä¸»è¦è§’è‰²: {json.dumps(outline.get('main_characters', [])[:3], ensure_ascii=False)}

åˆ†é›†å¤§çº²ï¼š
- æ ‡é¢˜: {episode_outline.get('title', '')}
- æ‘˜è¦: {episode_outline.get('summary', '')}
- å…³é”®åœºæ™¯: {json.dumps(episode_outline.get('key_scenes', []), ensure_ascii=False)}
- æ ¸å¿ƒå†²çª: {episode_outline.get('main_conflict', '')}
- é«˜æ½®ç‚¹: {episode_outline.get('climax', '')}
- ç»“å°¾æ‚¬å¿µ: {episode_outline.get('ending_hook', '')}
{context_text}
{previous_feedback}
è¦æ±‚ï¼š
1. ä½¿ç”¨æ ‡å‡†å‰§æœ¬æ ¼å¼
2. æ¯é›†æ—¶é•¿æ§åˆ¶åœ¨3-5åˆ†é’Ÿï¼ˆçº¦2000-3000å­—ï¼‰
3. åŒ…å«åœºæ™¯ã€äººç‰©ã€å¯¹è¯ã€åŠ¨ä½œ
4. å¯¹è¯è¦è‡ªç„¶ã€æœ‰å¼ åŠ›ï¼Œç¬¦åˆç”œå® é£æ ¼
5. åœºæ™¯æè¿°è¦è§†è§‰åŒ–
6. è¦æœ‰æ˜ç¡®çš„é•œå¤´è¯­è¨€æç¤º
7. å¼€å¤´è¦æœ‰å¸å¼•è§‚ä¼—çš„é’©å­
8. ç»“å°¾è¦æœ‰æ‚¬å¿µ
9. ä¸å‰é›†ä¿æŒæƒ…èŠ‚è¿è´¯æ€§

è¯·ä»¥æ ‡å‡†å‰§æœ¬æ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

ã€ç¬¬{episode_num}é›†ï¼š{episode_outline.get('title', '')}ã€‘

ã€åœºæ™¯1ï¼šåœ°ç‚¹ - æ—¶é—´ã€‘
[é•œå¤´ï¼šå…¨æ™¯/ä¸­æ™¯/è¿‘æ™¯/ç‰¹å†™]
[ç”»é¢æè¿°]
[äººç‰©åŠ¨ä½œ]

äººç‰©A: [å¯¹è¯å†…å®¹]

äººç‰©B: [å¯¹è¯å†…å®¹]

[åŠ¨ä½œæè¿°]

ã€åœºæ™¯2ï¼šåœ°ç‚¹ - æ—¶é—´ã€‘
..."""
    
    # ç”Ÿæˆå‰ï¼šä½¿ç”¨ optimize_script_prompt ä¼˜åŒ–åˆå§‹ promptï¼ˆä»…ç¬¬ä¸€é›†æˆ–æ¯5é›†ä¼˜åŒ–ä¸€æ¬¡ï¼‰
    shot_script_prompt = initial_prompt
    if episode_num == 1 or episode_num % 5 == 0:
        logger.info(f"  ğŸ”§ ç”Ÿæˆå‰è‡ªåŠ¨ä¼˜åŒ– promptï¼ˆç¬¬ {episode_num} é›†ï¼‰...")
        try:
            optimization_result = adapter.optimize_script_prompt(
                input_text=f"åˆ†é›†å¤§çº²ï¼š{episode_outline.get('summary', '')}\nå…³é”®åœºæ™¯ï¼š{json.dumps(episode_outline.get('key_scenes', []), ensure_ascii=False)}",
                execution_result="",  # é¦–æ¬¡ç”Ÿæˆï¼Œæ— æ‰§è¡Œç»“æœ
                current_prompt=initial_prompt
            )
            
            if optimization_result.get('optimized_prompt'):
                shot_script_prompt = optimization_result['optimized_prompt']
                logger.info(f"  âœ… Prompt å·²ä¼˜åŒ–ï¼ˆåŸºäºçŸ­å‰§å‰§æœ¬ç‰¹æ®Šéœ€æ±‚ï¼‰")
                
                # è®°å½•ä¼˜åŒ–å»ºè®®åˆ°ä¸Šä¸‹æ–‡
                if optimization_result.get('optimized_context', {}).get('script_specific'):
                    script_specific = optimization_result['optimized_context']['script_specific']
                    if script_specific.get('shot_design'):
                        logger.info(f"  ğŸ’¡ åˆ†é•œè®¾è®¡å»ºè®®: {script_specific['shot_design'][:100]}...")
                    if script_specific.get('dialogue_style'):
                        logger.info(f"  ğŸ’¡ å¯¹è¯é£æ ¼å»ºè®®: {script_specific['dialogue_style'][:100]}...")
            else:
                logger.info(f"  â„¹ï¸  æœªè·å¾—ä¼˜åŒ–å»ºè®®ï¼Œä½¿ç”¨åŸå§‹ prompt")
        except Exception as e:
            logger.warning(f"  âš ï¸  Prompt ä¼˜åŒ–è¿‡ç¨‹å‡ºé”™: {e}ï¼Œä½¿ç”¨åŸå§‹ prompt")
            shot_script_prompt = initial_prompt
    
    for attempt in range(max_retries + 1):
        try:
            from unimem.chat import ark_deepseek_v3_2
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ­å‰§å‰§æœ¬åˆ›ä½œåŠ©æ‰‹ï¼Œæ“…é•¿åˆ›ä½œæ ‡å‡†æ ¼å¼çš„çŸ­å‰§å‰§æœ¬ã€‚è¯·ä¿æŒèŠ‚å¥ç´§å‡‘ã€å¯¹è¯è‡ªç„¶ã€è§†è§‰åŒ–æè¿°ï¼Œç¬¦åˆç”œå® é£æ ¼ã€‚"},
                {"role": "user", "content": shot_script_prompt}
            ]
            
            _, response_text = ark_deepseek_v3_2(messages, max_new_tokens=2048)
            
            # æ¸…ç†å“åº”æ–‡æœ¬
            script = response_text.strip()
            if script.startswith("```"):
                lines = script.split('\n')
                script = '\n'.join([line for line in lines if not line.strip().startswith('```')])
            
            # åå‘ç»“æ„åŒ–æ ¡éªŒ
            validation_result = None
            if enable_validation:
                validation_result = validate_generated_script(
                    script, episode_outline, outline, adapter
                )
                
                accuracy_score = validation_result.get('accuracy_score', 0.5)
                
                if accuracy_score < validation_threshold and attempt < max_retries:
                    logger.warning(f"  âš ï¸ å‡†ç¡®åº¦è¯„åˆ† {accuracy_score:.2f} ä½äºé˜ˆå€¼ {validation_threshold}ï¼Œå°è¯•é‡æ–°ç”Ÿæˆ...")
                    
                    # ä½¿ç”¨ issues å’Œ suggestions æŒ‡å¯¼é‡æ–°ç”Ÿæˆ
                    enhanced_prompt = build_enhanced_prompt_with_feedback(
                        original_prompt=shot_script_prompt,
                        validation_result=validation_result,
                        attempt=attempt + 1
                    )
                    shot_script_prompt = enhanced_prompt
                    logger.info(f"  ğŸ“ å·²æ ¹æ®æ ¡éªŒåé¦ˆä¼˜åŒ– promptï¼ˆç¬¬ {attempt + 1} æ¬¡å°è¯•ï¼‰")
                    continue
                else:
                    logger.info(f"  âœ… æ ¡éªŒé€šè¿‡ï¼Œå‡†ç¡®åº¦è¯„åˆ†: {accuracy_score:.2f}")
                    if validation_result.get('issues'):
                        logger.info(f"  âš ï¸ å‘ç° {len(validation_result['issues'])} ä¸ªé—®é¢˜ï¼ˆä½†ä¸å½±å“ä½¿ç”¨ï¼‰")
                        # è®°å½• issues å’Œ suggestions ä¾›åç»­é›†å‚è€ƒ
                        if validation_result.get('suggestions'):
                            logger.info(f"  ğŸ’¡ ç”Ÿæˆ {len(validation_result['suggestions'])} æ¡ä¼˜åŒ–å»ºè®®ï¼ˆå·²è®°å½•ï¼‰")
                            if 'validation_feedback' not in outline:
                                outline['validation_feedback'] = []
                            outline['validation_feedback'].append({
                                'episode': episode_num,
                                'issues': validation_result.get('issues', [])[:3],
                                'suggestions': validation_result.get('suggestions', [])[:3]
                            })
            
            # ç”Ÿæˆåï¼šä½¿ç”¨ optimize_script_prompt åˆ†æç»“æœå¹¶ä¼˜åŒ–åç»­ promptï¼ˆæ¯é›†éƒ½åˆ†æï¼Œä½†ä»…è®°å½•ä¼˜åŒ–å»ºè®®ï¼‰
            if script and adapter.is_available():
                try:
                    logger.info(f"  ğŸ”§ ç”Ÿæˆåè‡ªåŠ¨åˆ†æå¹¶ä¼˜åŒ–ï¼ˆç”¨äºæŒ‡å¯¼åç»­é›†ï¼‰...")
                    post_optimization = adapter.optimize_script_prompt(
                        input_text=f"åˆ†é›†å¤§çº²ï¼š{episode_outline.get('summary', '')}",
                        execution_result=script[:1000],  # ä½¿ç”¨ç”Ÿæˆç»“æœçš„å‰1000å­—è¿›è¡Œåˆ†æ
                        current_prompt=shot_script_prompt
                    )
                    
                    # å°†ä¼˜åŒ–å»ºè®®å­˜å‚¨åˆ° outline ä¸­ï¼Œä¾›åç»­é›†å‚è€ƒ
                    if post_optimization.get('analysis', {}).get('suggestions'):
                        if 'optimization_feedback' not in outline:
                            outline['optimization_feedback'] = []
                        outline['optimization_feedback'].append({
                            'episode': episode_num,
                            'suggestions': post_optimization['analysis'].get('suggestions', [])[:3],
                            'script_specific': post_optimization.get('optimized_context', {}).get('script_specific', {})
                        })
                        logger.info(f"  âœ… å·²è®°å½•ä¼˜åŒ–å»ºè®®ä¾›åç»­é›†å‚è€ƒ")
                except Exception as e:
                    logger.warning(f"  âš ï¸  ç”Ÿæˆåä¼˜åŒ–åˆ†æå‡ºé”™: {e}ï¼ˆä¸å½±å“ç”Ÿæˆï¼‰")
            
            logger.info(f"âœ… ç¬¬ {episode_num} é›†å‰§æœ¬ç”Ÿæˆå®Œæˆ ({len(script)} å­—)")
            return script, validation_result
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆç¬¬ {episode_num} é›†å‰§æœ¬å¤±è´¥: {e}")
            if attempt < max_retries:
                logger.info(f"  é‡è¯•ä¸­... ({attempt + 1}/{max_retries})")
                import time
                time.sleep(1)
                continue
            return "", None
    
    return "", None


def main():
    """ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–é€‚é…å™¨
    config = {
        'local_model_path': '/root/data/AI/pretrain/multilingual-e5-small',
        'qdrant_host': 'localhost',
        'qdrant_port': 6333,
        'collection_name': 'script_creation'
    }
    
    adapter = ScriptAdapter(config)
    adapter.initialize()
    
    # é€‰æ‹©ä¸»é¢˜
    data_dir = Path(__file__).parent.parent.parent / 'data'
    test_outline_file = data_dir / 'test_script_outline.json'
    test_outlines_file = data_dir / 'test_script_episode_outlines.json'
    
    # ä¼˜å…ˆä½¿ç”¨æµ‹è¯•é€šè¿‡çš„å¤§çº²
    if test_outline_file.exists() and test_outlines_file.exists():
        logger.info("âœ… ä½¿ç”¨æµ‹è¯•é€šè¿‡çš„å¤§çº²æ–‡ä»¶...")
        with open(test_outline_file, 'r', encoding='utf-8') as f:
            outline = json.load(f)
        with open(test_outlines_file, 'r', encoding='utf-8') as f:
            outlines_data = json.load(f)
            episode_outlines = outlines_data.get('episode_outlines', [])
        
        logger.info(f"ä½œå“æ ‡é¢˜: {outline.get('title', '')}")
        logger.info(f"é¢˜æç±»å‹: {outline.get('genre', '')}")
        logger.info(f"åˆ†é›†å¤§çº²: {len(episode_outlines)} é›†ï¼ˆå·²åŠ è½½ï¼‰")
        
        # éªŒè¯å®Œæ•´æ€§
        if len(episode_outlines) < 50:
            logger.warning(f"âš ï¸ åˆ†é›†å¤§çº²ä¸å®Œæ•´ï¼šåªæœ‰ {len(episode_outlines)}/50 é›†ï¼Œå°†é‡æ–°ç”Ÿæˆ")
            episode_outlines = None
    else:
        episode_outlines = None
    
    # å¦‚æœæ²¡æœ‰æµ‹è¯•å¤§çº²ï¼Œåˆ™ç”Ÿæˆæ–°çš„å¤§çº²
    if episode_outlines is None:
        theme = "ç”œå® "
        logger.info(f"é€‰æ‹©ä¸»é¢˜: {theme}")
        
        # 1. ç”Ÿæˆæ•…äº‹å¤§çº²
        outline_json = generate_script_outline(adapter, theme)
        if not outline_json:
            logger.error("æ•…äº‹å¤§çº²ç”Ÿæˆå¤±è´¥ï¼Œé€€å‡º")
            return
        
        outline = json.loads(outline_json)
        logger.info(f"ä½œå“æ ‡é¢˜: {outline.get('title', '')}")
        logger.info(f"é¢˜æç±»å‹: {outline.get('genre', '')}")
        
        # ä¿å­˜å¤§çº²
        outline_file = data_dir / 'script_outline.json'
        with open(outline_file, 'w', encoding='utf-8') as f:
            json.dump(outline, f, ensure_ascii=False, indent=2)
        logger.info(f"å¤§çº²å·²ä¿å­˜åˆ°: {outline_file}")
        
        # 2. ç”Ÿæˆåˆ†é›†å¤§çº²ï¼ˆ50é›†ï¼‰
        episode_outlines = generate_episode_outlines(adapter, outline, num_episodes=50)
    
    if not episode_outlines:
        logger.error("åˆ†é›†å¤§çº²ç”Ÿæˆå¤±è´¥ï¼Œé€€å‡º")
        return
    
    # æœ€ç»ˆå®Œæ•´æ€§éªŒè¯
    if len(episode_outlines) < 50:
        logger.error(f"âŒ åˆ†é›†å¤§çº²ä¸å®Œæ•´ï¼šåªæœ‰ {len(episode_outlines)}/50 é›†ï¼Œé€€å‡º")
        return
    
    # ä¿å­˜åˆ†é›†å¤§çº²
    outlines_file = data_dir / 'script_episode_outlines.json'
    with open(outlines_file, 'w', encoding='utf-8') as f:
        json.dump({"episode_outlines": episode_outlines}, f, ensure_ascii=False, indent=2)
    logger.info(f"åˆ†é›†å¤§çº²å·²ä¿å­˜åˆ°: {outlines_file}")
    
    # éªŒè¯ä¿å­˜çš„æ–‡ä»¶
    with open(outlines_file, 'r', encoding='utf-8') as f:
        saved_data = json.load(f)
        saved_count = len(saved_data.get('episode_outlines', []))
        logger.info(f"âœ… éªŒè¯ï¼šä¿å­˜çš„æ–‡ä»¶åŒ…å« {saved_count} é›†")
    
    # 3. ç”Ÿæˆå®Œæ•´å‰§æœ¬ï¼ˆé€é›†ç”Ÿæˆï¼Œæ¯é›†ä½¿ç”¨ä¸Šä¸‹æ–‡å’Œåå‘ç»“æ„åŒ–æ ¡éªŒï¼‰
    num_episodes_to_generate = len(episode_outlines)
    logger.info(f"\nç”Ÿæˆå…¨éƒ¨ {num_episodes_to_generate} é›†å®Œæ•´å‰§æœ¬ï¼ˆé€é›†ç”Ÿæˆï¼Œå¸¦ä¸Šä¸‹æ–‡å’Œæ ¡éªŒï¼‰...")
    logger.info(f"æ ¡éªŒæ¨¡å¼: å‰ 5 é›†å¼ºåˆ¶æ ¡éªŒï¼Œé˜ˆå€¼ 0.7")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    script_dir = data_dir / 'script'
    script_dir.mkdir(exist_ok=True)
    logger.info(f"å‰§æœ¬ä¿å­˜ç›®å½•: {script_dir}")
    
    scripts = []
    context_memories = []  # ç”¨äºç´¯ç§¯ä¸Šä¸‹æ–‡è®°å¿†
    validate_first_n = 5  # å‰5é›†å¼ºåˆ¶æ ¡éªŒ
    
    # é€é›†ç”Ÿæˆï¼ˆä¸ä½¿ç”¨æ‰¹æ¬¡ï¼‰
    for i, ep_outline in enumerate(episode_outlines, 1):
        episode_num = ep_outline.get('episode_num', i)
        
        # å†³å®šæ˜¯å¦å¯ç”¨æ ¡éªŒï¼šå‰Né›†å¼ºåˆ¶æ ¡éªŒï¼Œå…¶ä½™ç« èŠ‚å¯é€‰
        should_validate = episode_num <= validate_first_n
        
        script, validation_result = generate_full_script(
            adapter=adapter,
            episode_outline=ep_outline,
            outline=outline,
            context_memories=context_memories,
            enable_validation=should_validate,
            validation_threshold=0.7,
            max_retries=2
        )
        
        if script:
            script_data = {
                "episode_num": episode_num,
                "title": ep_outline.get('title', f'ç¬¬{episode_num}é›†'),
                "outline": ep_outline,
                "script": script,
                "word_count": len(script)
            }
            
            # æ·»åŠ æ ¡éªŒç»“æœ
            if validation_result:
                script_data['validation'] = {
                    'accuracy_score': validation_result.get('accuracy_score', 0),
                    'coverage': validation_result.get('coverage', {}),
                    'issues': validation_result.get('issues', []),
                    'suggestions': validation_result.get('suggestions', [])
                }
            
            scripts.append(script_data)
            
            # ç«‹å³ä¿å­˜å•é›†å‰§æœ¬åˆ°æ–‡ä»¶
            episode_file = script_dir / f"episode_{episode_num:02d}.json"
            with open(episode_file, 'w', encoding='utf-8') as f:
                json.dump(script_data, f, ensure_ascii=False, indent=2)
            
            # åŒæ—¶ä¿å­˜çº¯æ–‡æœ¬ç‰ˆæœ¬
            episode_txt_file = script_dir / f"episode_{episode_num:02d}.txt"
            with open(episode_txt_file, 'w', encoding='utf-8') as f:
                f.write(f"ç¬¬{episode_num}é›†ï¼š{script_data['title']}\n")
                f.write("="*60 + "\n\n")
                f.write(script)
            
            logger.info(f"  âœ… ç¬¬ {episode_num} é›†å®Œæˆ ({len(script)} å­—) - å·²ä¿å­˜åˆ° {episode_file.name}")
            
            # å°†ç”Ÿæˆçš„å‰§æœ¬å†…å®¹å­˜å‚¨ä¸ºè®°å¿†ï¼Œç”¨äºåç»­é›†çš„ä¸Šä¸‹æ–‡
            if adapter.is_available():
                memory = adapter.construct_script_note(
                    content=script[:1000],  # åªå­˜å‚¨éƒ¨åˆ†å†…å®¹ä½œä¸ºä¸Šä¸‹æ–‡
                    timestamp=datetime.now(),
                    entities=[],
                    generate_summary=False
                )
                context_memories.append(memory)
                if len(context_memories) > 3:  # åªä¿ç•™æœ€è¿‘3é›†ä½œä¸ºä¸Šä¸‹æ–‡
                    context_memories = context_memories[-3:]
        
        # æ·»åŠ å»¶è¿Ÿé¿å… API é™æµ
        import time
        if i < num_episodes_to_generate:
            time.sleep(1)
    
    # ä¿å­˜å®Œæ•´å‰§æœ¬æ±‡æ€»ï¼ˆæ‰€æœ‰é›†æ•°å·²å•ç‹¬ä¿å­˜ï¼Œè¿™é‡Œä¿å­˜æ±‡æ€»ï¼‰
    scripts_file = data_dir / 'script_episodes.json'
    scripts_data = {
        "novel_info": {
            "title": outline.get('title', ''),
            "genre": outline.get('genre', ''),
            "theme": outline.get('theme', ''),
            "total_episodes": num_episodes_to_generate,
            "generated_episodes": len(scripts)
        },
        "episodes": scripts
    }
    with open(scripts_file, 'w', encoding='utf-8') as f:
        json.dump(scripts_data, f, ensure_ascii=False, indent=2)
    logger.info(f"å®Œæ•´å‰§æœ¬æ±‡æ€»å·²ä¿å­˜åˆ°: {scripts_file}")
    
    # ç”Ÿæˆçº¯æ–‡æœ¬æ±‡æ€»ç‰ˆæœ¬
    txt_file = data_dir / 'script_episodes.txt'
    with open(txt_file, 'w', encoding='utf-8') as f:
        f.write(f"{outline.get('title', 'çŸ­å‰§å‰§æœ¬')}\n")
        f.write("="*60 + "\n\n")
        for script_data in scripts:
            f.write(f"ç¬¬{script_data['episode_num']}é›†ï¼š{script_data['title']}\n")
            f.write("-"*60 + "\n\n")
            f.write(script_data['script'])
            f.write("\n\n")
    logger.info(f"çº¯æ–‡æœ¬æ±‡æ€»ç‰ˆæœ¬å·²ä¿å­˜åˆ°: {txt_file}")
    logger.info(f"å•é›†å‰§æœ¬æ–‡ä»¶å·²ä¿å­˜åˆ°: {script_dir}/")
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    logger.info("\n" + "="*60)
    logger.info("ç”Ÿæˆç»Ÿè®¡")
    logger.info("="*60)
    logger.info(f"æ€»é›†æ•°: 50 é›†")
    logger.info(f"åˆ†é›†å¤§çº²: {len(episode_outlines)} é›†")
    logger.info(f"å®Œæ•´å‰§æœ¬: {len(scripts)} é›†")
    if scripts:
        total_words = sum(s.get('word_count', 0) for s in scripts)
        logger.info(f"æ€»å­—æ•°: {total_words:,} å­—")
        logger.info(f"å¹³å‡æ¯é›†: {total_words // len(scripts) if scripts else 0} å­—")
    
    logger.info("\nâœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")


if __name__ == "__main__":
    main()

