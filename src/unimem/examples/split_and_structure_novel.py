"""
æ‹†åˆ†å°è¯´ç« èŠ‚å¹¶ç»“æ„åŒ–å‰5ç« 
ç„¶ååŸºäºåˆ†æç»“æœæå‡ºæ–°çš„æ­¦ä¾ åˆ›ä½œ idea

åŠŸèƒ½ï¼š
1. æ‹†åˆ†å°è¯´ç« èŠ‚
2. ç»“æ„åŒ–å‰Nç« ï¼ˆä½¿ç”¨ AtomLinkAdapterï¼‰
3. åŸºäºåˆ†æç»“æœç”Ÿæˆæ–°çš„æ­¦ä¾ åˆ›ä½œ idea

è¿è¡Œå‰ç¡®ä¿ï¼š
1. å·²æ¿€æ´» myswift ç¯å¢ƒï¼šconda activate myswift
2. Qdrant æœåŠ¡å·²å¯åŠ¨ï¼ˆlocalhost:6333ï¼‰
3. å°è¯´æ–‡ä»¶å­˜åœ¨ï¼šdata/é‡‘åº¸-ç¬‘å‚²æ±Ÿæ¹–.txt
"""

import sys
import re
import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from unimem.adapters.atom_link_adapter import AtomLinkAdapter
from unimem.types import Memory, Entity
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def split_chapters(novel_file: Path) -> List[Dict[str, Any]]:
    """
    æ‹†åˆ†ç« èŠ‚
    
    Args:
        novel_file: å°è¯´æ–‡ä»¶è·¯å¾„
        
    Returns:
        ç« èŠ‚åˆ—è¡¨ï¼Œæ¯ä¸ªç« èŠ‚åŒ…å« title, content, start_line
    """
    content = novel_file.read_text(encoding='utf-8')
    lines = content.split('\n')
    
    chapters = []
    current_chapter = None
    current_content = []
    current_start_line = 0
    
    ***REMOVED*** ç« èŠ‚æ ‡é¢˜æ¨¡å¼ï¼šé¡¶æ ¼ï¼Œæ ¼å¼ä¸º"æ•°å­—+ç©ºæ ¼+æ ‡é¢˜"
    chapter_pattern = r'^([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡]+|[0-9]+)\s+([^\n]+)$'
    
    for i, line in enumerate(lines):
        ***REMOVED*** æ£€æŸ¥æ˜¯å¦æ˜¯ç« èŠ‚æ ‡é¢˜ï¼ˆé¡¶æ ¼ï¼Œä¸ç¼©è¿›ï¼‰
        stripped = line.strip()
        if stripped and not line.startswith('ã€€') and not line.startswith(' ') and re.match(chapter_pattern, stripped):
            ***REMOVED*** ä¿å­˜ä¸Šä¸€ç« 
            if current_chapter:
                chapters.append({
                    'title': current_chapter,
                    'content': '\n'.join(current_content).strip(),
                    'start_line': current_start_line
                })
            ***REMOVED*** å¼€å§‹æ–°ç« 
            current_chapter = stripped
            current_content = []
            current_start_line = i + 1
        elif current_chapter:
            ***REMOVED*** å±äºå½“å‰ç« èŠ‚çš„å†…å®¹ï¼ˆä¿ç•™åŸå§‹æ ¼å¼ï¼‰
            current_content.append(line)
    
    ***REMOVED*** ä¿å­˜æœ€åä¸€ç« 
    if current_chapter:
        chapters.append({
            'title': current_chapter,
            'content': '\n'.join(current_content).strip(),
            'start_line': current_start_line
        })
    
    return chapters


def structure_chapters(
    chapters: List[Dict[str, Any]], 
    adapter: AtomLinkAdapter, 
    num_chapters: int = 5
) -> List[Dict[str, Any]]:
    """
    ç»“æ„åŒ–å‰Nç« 
    
    Args:
        chapters: ç« èŠ‚åˆ—è¡¨
        adapter: AtomLinkAdapter å®ä¾‹
        num_chapters: è¦ç»“æ„åŒ–çš„ç« èŠ‚æ•°é‡
        
    Returns:
        ç»“æ„åŒ–åçš„ç« èŠ‚åˆ—è¡¨
    """
    logger.info(f"å¼€å§‹ç»“æ„åŒ–å‰ {num_chapters} ç« ...")
    
    structured_chapters = []
    
    for i, chapter in enumerate(chapters[:num_chapters], 1):
        logger.info(f"\nå¤„ç†ç¬¬ {i} ç« : {chapter['title']}")
        logger.info(f"å†…å®¹é•¿åº¦: {len(chapter['content'])} å­—ç¬¦")
        
        ***REMOVED*** ä½¿ç”¨åˆ›ä½œå†…å®¹åˆ†æ
        analysis = adapter._analyze_content(
            chapter['content'][:2000],  ***REMOVED*** é™åˆ¶é•¿åº¦é¿å…è¿‡é•¿
            is_creative_content=True
        )
        
        ***REMOVED*** æ„å»ºåŸå­ç¬”è®°
        memory = adapter.construct_atomic_note(
            content=chapter['content'][:2000],
            timestamp=datetime.now(),
            entities=[],
            generate_summary=True,
            is_creative_content=True
        )
        
        ***REMOVED*** æ·»åŠ åˆ°å‘é‡å­˜å‚¨
        adapter.add_memory_to_vector_store(memory)
        
        structured_chapters.append({
            'chapter_num': i,
            'title': chapter['title'],
            'memory_id': memory.id,
            'keywords': analysis.get('keywords', []),
            'context': analysis.get('context', ''),
            'tags': analysis.get('tags', []),
            'creative_dimensions': analysis.get('creative_dimensions', {}),
            'summary': memory.content[:300]  ***REMOVED*** æ‘˜è¦
        })
        
        logger.info(f"âœ… ç¬¬ {i} ç« ç»“æ„åŒ–å®Œæˆ")
        logger.info(f"  å…³é”®è¯: {', '.join(analysis.get('keywords', [])[:5])}")
        logger.info(f"  ç±»å‹: {analysis.get('creative_dimensions', {}).get('genre', 'N/A')}")
    
    return structured_chapters


def generate_creative_idea(
    structured_chapters: List[Dict[str, Any]], 
    adapter: AtomLinkAdapter
) -> Dict[str, Any]:
    """
    åŸºäºç»“æ„åŒ–ç»“æœç”Ÿæˆæ–°çš„æ­¦ä¾ åˆ›ä½œ idea
    
    Args:
        structured_chapters: ç»“æ„åŒ–åçš„ç« èŠ‚åˆ—è¡¨
        adapter: AtomLinkAdapter å®ä¾‹
        
    Returns:
        åˆ›ä½œ idea å­—å…¸
    """
    logger.info("\n" + "="*50)
    logger.info("åŸºäºåˆ†æç»“æœç”Ÿæˆæ–°çš„æ­¦ä¾ åˆ›ä½œ idea...")
    logger.info("="*50)
    
    ***REMOVED*** æå–å…³é”®ä¿¡æ¯
    genres = []
    styles = []
    characters = []
    events = []
    themes = []
    
    for ch in structured_chapters:
        dims = ch.get('creative_dimensions', {})
        if dims.get('genre'):
            genres.append(dims['genre'])
        if dims.get('writing_style'):
            styles.append(dims['writing_style'])
        if dims.get('characters'):
            characters.extend(dims['characters'])
        if dims.get('events'):
            events.extend(dims['events'])
        if ch.get('tags'):
            themes.extend(ch['tags'])
    
    ***REMOVED*** æ„å»º prompt
    prompt = f"""åŸºäºå¯¹ã€Šç¬‘å‚²æ±Ÿæ¹–ã€‹å‰5ç« çš„ç»“æ„åŒ–åˆ†æï¼Œè¯·åˆ›ä½œä¸€ä¸ªå…¨æ–°çš„æ­¦ä¾ å°è¯´ ideaã€‚

åˆ†æç»“æœï¼š
- ä½œå“ç±»å‹: {', '.join(set(genres))}
- å†™ä½œé£æ ¼: {', '.join(set(styles))}
- ä¸»è¦äººç‰©ç±»å‹: {len(characters)} ä¸ªè§’è‰²
- å…³é”®äº‹ä»¶ç±»å‹: {len(events)} ä¸ªäº‹ä»¶
        - ä¸»é¢˜æ ‡ç­¾: {', '.join(list(set(themes))[:10])}

è¦æ±‚ï¼š
1. åˆ›ä½œä¸€ä¸ªå…¨æ–°çš„æ­¦ä¾ æ•…äº‹ ideaï¼Œä¸è¦é‡å¤ã€Šç¬‘å‚²æ±Ÿæ¹–ã€‹çš„æƒ…èŠ‚
2. å¯ä»¥å€Ÿé‰´å…¶å™äº‹é£æ ¼å’Œç»“æ„ï¼Œä½†è¦æœ‰åˆ›æ–°
3. åŒ…å«ï¼šæ•…äº‹èƒŒæ™¯ã€ä¸»è¦äººç‰©ã€æ ¸å¿ƒå†²çªã€ç‹¬ç‰¹è®¾å®š
4. è¦æœ‰å¸å¼•äººçš„å¼€ç¯‡æƒ…èŠ‚

è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼š
{{
    "title": "ä½œå“æ ‡é¢˜",
    "genre": "ä½œå“ç±»å‹",
    "background": "æ•…äº‹èƒŒæ™¯ï¼ˆæ—¶ä»£ã€åœ°ç‚¹ã€ä¸–ç•Œè§‚ï¼‰",
    "main_characters": [
        {{"name": "è§’è‰²å", "role": "è§’è‰²å®šä½", "characteristics": "æ€§æ ¼ç‰¹å¾"}},
        ...
    ],
    "core_conflict": "æ ¸å¿ƒå†²çª",
    "unique_setting": "ç‹¬ç‰¹è®¾å®šï¼ˆåŒºåˆ«äºä¼ ç»Ÿæ­¦ä¾ çš„åˆ›æ–°ç‚¹ï¼‰",
    "opening_scene": "å¼€ç¯‡åœºæ™¯æè¿°",
    "writing_style": "å»ºè®®çš„å†™ä½œé£æ ¼",
    "themes": ["ä¸»é¢˜1", "ä¸»é¢˜2", ...]
}}"""
    
    try:
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ­¦ä¾ å°è¯´åˆ›ä½œåŠ©æ‰‹ï¼Œæ“…é•¿åŸºäºç»å…¸ä½œå“åˆ†æåˆ›ä½œå…¨æ–°çš„æ­¦ä¾ æ•…äº‹ã€‚è¯·å§‹ç»ˆä»¥æœ‰æ•ˆçš„ JSON æ ¼å¼è¿”å›ç»“æœã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        from unimem.chat import ark_deepseek_v3_2
        _, response_text = ark_deepseek_v3_2(messages, max_new_tokens=2048)
        
        result = adapter._parse_json_response(response_text)
        
        if result:
            return result
        else:
            logger.warning("æ— æ³•è§£æ JSONï¼Œè¿”å›æ–‡æœ¬")
            return {"raw_response": response_text}
    except Exception as e:
        logger.error(f"ç”Ÿæˆåˆ›ä½œ idea å¤±è´¥: {e}")
        return {}


def main() -> None:
    """
    ä¸»å‡½æ•°
    
    æ‰§è¡Œå®Œæ•´çš„æµç¨‹ï¼šæ‹†åˆ†ç« èŠ‚ -> ç»“æ„åŒ– -> ç”Ÿæˆåˆ›ä½œ idea
    """
    ***REMOVED*** åˆå§‹åŒ–é€‚é…å™¨
    config = {
        'local_model_path': '/root/data/AI/pretrain/multilingual-e5-small',
        'qdrant_host': 'localhost',
        'qdrant_port': 6333,
        'collection_name': 'xiaoaohujiang_analysis'
    }
    
    try:
        adapter = AtomLinkAdapter(config)
        adapter.initialize()
        
        if not adapter.is_available():
            logger.error("é€‚é…å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’ŒæœåŠ¡")
            return
    except Exception as e:
        logger.error(f"åˆå§‹åŒ–é€‚é…å™¨å¤±è´¥: {e}")
        return
    
    ***REMOVED*** 1. æ‹†åˆ†ç« èŠ‚
    novel_file = Path(__file__).parent.parent.parent / 'data' / 'é‡‘åº¸-ç¬‘å‚²æ±Ÿæ¹–.txt'
    logger.info(f"è¯»å–å°è¯´æ–‡ä»¶: {novel_file}")
    
    if not novel_file.exists():
        logger.error(f"å°è¯´æ–‡ä»¶ä¸å­˜åœ¨: {novel_file}")
        return
    
    try:
        chapters = split_chapters(novel_file)
        logger.info(f"âœ… æˆåŠŸæ‹†åˆ† {len(chapters)} ä¸ªç« èŠ‚")
    except Exception as e:
        logger.error(f"æ‹†åˆ†ç« èŠ‚å¤±è´¥: {e}")
        return
    
    ***REMOVED*** æ˜¾ç¤ºå‰10ç« æ ‡é¢˜
    logger.info("\nå‰10ç« æ ‡é¢˜:")
    for i, ch in enumerate(chapters[:10], 1):
        logger.info(f"  {i}. {ch['title']} (è¡Œ {ch['start_line']}, {len(ch['content'])} å­—ç¬¦)")
    
    ***REMOVED*** 2. ç»“æ„åŒ–å‰5ç« 
    structured = structure_chapters(chapters, adapter, num_chapters=5)
    
    ***REMOVED*** ä¿å­˜ç»“æ„åŒ–ç»“æœ
    output_file = Path(__file__).parent.parent.parent / 'data' / 'xiaoaohujiang_structured.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(structured, f, ensure_ascii=False, indent=2)
    logger.info(f"\nâœ… ç»“æ„åŒ–ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    ***REMOVED*** 3. ç”Ÿæˆæ–°çš„æ­¦ä¾ åˆ›ä½œ idea
    creative_idea = generate_creative_idea(structured, adapter)
    
    ***REMOVED*** ä¿å­˜åˆ›ä½œ idea
    idea_file = Path(__file__).parent.parent.parent / 'data' / 'new_wuxia_idea.json'
    with open(idea_file, 'w', encoding='utf-8') as f:
        json.dump(creative_idea, f, ensure_ascii=False, indent=2)
    logger.info(f"âœ… åˆ›ä½œ idea å·²ä¿å­˜åˆ°: {idea_file}")
    
    ***REMOVED*** æ‰“å°åˆ›ä½œ idea
    logger.info("\n" + "="*50)
    logger.info("ğŸ¨ æ–°çš„æ­¦ä¾ åˆ›ä½œ IDEA")
    logger.info("="*50)
    if isinstance(creative_idea, dict) and 'title' in creative_idea:
        logger.info(f"æ ‡é¢˜: {creative_idea.get('title')}")
        logger.info(f"ç±»å‹: {creative_idea.get('genre')}")
        logger.info(f"\næ•…äº‹èƒŒæ™¯:\n{creative_idea.get('background', '')}")
        logger.info(f"\næ ¸å¿ƒå†²çª:\n{creative_idea.get('core_conflict', '')}")
        logger.info(f"\nç‹¬ç‰¹è®¾å®š:\n{creative_idea.get('unique_setting', '')}")
        logger.info(f"\nä¸»è¦äººç‰©:")
        for char in creative_idea.get('main_characters', [])[:3]:
            logger.info(f"  - {char.get('name')}: {char.get('role')} ({char.get('characteristics')})")
        logger.info(f"\nå¼€ç¯‡åœºæ™¯:\n{creative_idea.get('opening_scene', '')[:300]}...")
    else:
        logger.info(json.dumps(creative_idea, ensure_ascii=False, indent=2))
    
    logger.info("\nâœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")


if __name__ == "__main__":
    main()

