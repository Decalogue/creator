"""
å®Œæ•´å°è¯´åˆ›ä½œæµç¨‹æµ‹è¯•è„šæœ¬

æµ‹è¯•ä» idea åˆ°å®Œæ•´å°è¯´çš„ç«¯åˆ°ç«¯æµç¨‹
"""
import sys
import logging
from pathlib import Path
from datetime import datetime

sys.path.insert(0, str(Path(__file__).parent.parent))

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

from novel_creation.react_novel_creator import ReactNovelCreator

logger = logging.getLogger(__name__)


def test_full_novel_creation(
    novel_title: str = "æµ‹è¯•å°è¯´",
    genre: str = "ç§‘å¹»",
    theme: str = "æ—¶é—´æ—…è¡Œä¸å¹³è¡Œä¸–ç•Œ",
    target_chapters: int = 5,
    words_per_chapter: int = 2000
):
    """
    æµ‹è¯•å®Œæ•´å°è¯´åˆ›ä½œæµç¨‹
    
    Args:
        novel_title: å°è¯´æ ‡é¢˜
        genre: å°è¯´ç±»å‹
        theme: ä¸»é¢˜
        target_chapters: ç›®æ ‡ç« èŠ‚æ•°
        words_per_chapter: æ¯ç« ç›®æ ‡å­—æ•°
    """
    print("=" * 70)
    print("å®Œæ•´å°è¯´åˆ›ä½œæµç¨‹æµ‹è¯•")
    print("=" * 70)
    print()
    print(f"ğŸ“– å°è¯´æ ‡é¢˜: {novel_title}")
    print(f"ğŸ“š ç±»å‹: {genre}")
    print(f"ğŸ¯ ä¸»é¢˜: {theme}")
    print(f"ğŸ“‘ ç« èŠ‚æ•°: {target_chapters} ç« ")
    print(f"ğŸ“ æ¯ç« å­—æ•°: {words_per_chapter} å­—")
    print()
    
    ***REMOVED*** åˆ›å»ºåˆ›ä½œå™¨ï¼ˆå¯ç”¨æ‰€æœ‰ä¼˜åŒ–åŠŸèƒ½ï¼‰
    print("=" * 70)
    print("åˆå§‹åŒ–åˆ›ä½œå™¨...")
    print("=" * 70)
    
    try:
        creator = ReactNovelCreator(
            novel_title=novel_title,
            enable_context_offloading=True,
            enable_creative_context=True,
            enable_enhanced_extraction=True,
            enable_unimem=False,  ***REMOVED*** å…ˆä¸ä½¿ç”¨ UniMem
            enable_quality_check=True
        )
        print("âœ… åˆ›ä½œå™¨åˆå§‹åŒ–æˆåŠŸ")
        print()
        print("ä¼˜åŒ–åŠŸèƒ½çŠ¶æ€ï¼š")
        ***REMOVED*** æ£€æŸ¥å±æ€§æ˜¯å¦å­˜åœ¨
        if hasattr(creator, '_enable_context_offloading'):
            print(f"  âœ… ä¸Šä¸‹æ–‡å¸è½½: {creator._enable_context_offloading}")
        if hasattr(creator, 'enable_creative_context'):
            print(f"  âœ… åˆ›ä½œä¸Šä¸‹æ–‡: {creator.enable_creative_context}")
        if hasattr(creator, 'enable_enhanced_extraction'):
            print(f"  âœ… å¢å¼ºå®ä½“æå–: {creator.enable_enhanced_extraction}")
        if hasattr(creator, 'enable_quality_check'):
            print(f"  âœ… è´¨é‡æ£€æŸ¥: {creator.enable_quality_check}")
        print()
    except Exception as e:
        print(f"âŒ åˆ›ä½œå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None
    
    ***REMOVED*** å¼€å§‹åˆ›ä½œ
    print("=" * 70)
    print("å¼€å§‹åˆ›ä½œ...")
    print("=" * 70)
    print()
    
    start_time = datetime.now()
    
    try:
        result = creator.create_novel(
            genre=genre,
            theme=theme,
            target_chapters=target_chapters,
            words_per_chapter=words_per_chapter,
            start_from_chapter=1
        )
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print()
        print("=" * 70)
        print("âœ… åˆ›ä½œå®Œæˆï¼")
        print("=" * 70)
        print()
        print(f"ğŸ“– å°è¯´æ ‡é¢˜: {result['novel_title']}")
        print(f"ğŸ“‘ æ€»ç« èŠ‚æ•°: {result['total_chapters']}")
        print(f"ğŸ“ æ€»å­—æ•°: {result['total_words']:,} å­—")
        print(f"â±ï¸  è€—æ—¶: {duration:.1f} ç§’")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {result['output_dir']}")
        print()
        
        ***REMOVED*** æ˜¾ç¤ºä¼˜åŒ–æ•ˆæœ
        _show_optimization_results(result['output_dir'])
        
        return result
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ åˆ›ä½œå·²ä¸­æ–­")
        return None
    except Exception as e:
        print(f"\n\nâŒ åˆ›ä½œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def _show_optimization_results(output_dir: str):
    """æ˜¾ç¤ºä¼˜åŒ–æ•ˆæœç»Ÿè®¡"""
    import json
    
    metadata_file = Path(output_dir) / "metadata.json"
    if not metadata_file.exists():
        print("âš ï¸ å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    try:
        metadata = json.loads(metadata_file.read_text(encoding='utf-8'))
        
        print("=" * 70)
        print("ä¼˜åŒ–æ•ˆæœç»Ÿè®¡")
        print("=" * 70)
        print()
        
        ***REMOVED*** å¢å¼ºæå–æ•ˆæœ
        enhanced = metadata.get('enhanced_extraction', {})
        if enhanced.get('enabled'):
            print("âœ… å¢å¼ºå®ä½“æå–:")
            print(f"   æ–¹æ³•: {enhanced.get('method', 'N/A')}")
            print()
        
        ***REMOVED*** åˆ›ä½œä¸Šä¸‹æ–‡æ•ˆæœ
        creative = metadata.get('creative_context', {})
        if creative.get('enabled'):
            entities_count = creative.get('entities_count', 0)
            relations_count = creative.get('relations_count', 0)
            chapters = metadata.get('total_chapters', 1)
            entities_per_chapter = entities_count / chapters if chapters > 0 else 0
            
            print("âœ… åˆ›ä½œä¸Šä¸‹æ–‡:")
            print(f"   å®ä½“æ€»æ•°: {entities_count}")
            print(f"   å…³ç³»æ€»æ•°: {relations_count}")
            print(f"   å¹³å‡å®ä½“æ•°/ç« : {entities_per_chapter:.1f}")
            print(f"   ç›®æ ‡: 5+ å®ä½“/ç« ")
            print(f"   çŠ¶æ€: {'âœ… è¾¾æ ‡' if entities_per_chapter >= 5 else 'âš ï¸  æœªè¾¾æ ‡'}")
            print()
        
        ***REMOVED*** è´¨é‡æ£€æŸ¥æ•ˆæœ
        quality = metadata.get('quality_check', {})
        if quality.get('enabled'):
            total_issues = quality.get('total_issues', 0)
            high_severity = quality.get('high_severity_chapters', 0)
            
            print("âœ… è´¨é‡æ£€æŸ¥:")
            print(f"   å‘ç°é—®é¢˜: {total_issues} ä¸ª")
            print(f"   ä¸¥é‡é—®é¢˜ç« èŠ‚: {high_severity} ä¸ª")
            if total_issues == 0:
                print(f"   çŠ¶æ€: âœ… æœªå‘ç°é—®é¢˜")
            elif high_severity == 0:
                print(f"   çŠ¶æ€: âš ï¸  æœ‰è½»å¾®é—®é¢˜")
            else:
                print(f"   çŠ¶æ€: âš ï¸  æœ‰ä¸¥é‡é—®é¢˜")
            print()
        
        ***REMOVED*** æ–‡ä»¶è¾“å‡º
        print("=" * 70)
        print("è¾“å‡ºæ–‡ä»¶")
        print("=" * 70)
        print()
        print(f"ğŸ“„ å®Œæ•´å°è¯´: {output_dir}/{metadata.get('novel_title', 'å°è¯´')}_å®Œæ•´ç‰ˆ.txt")
        print(f"ğŸ“Š å…ƒæ•°æ®: {output_dir}/metadata.json")
        print(f"ğŸ“‹ å¤§çº²: {output_dir}/novel_plan.json")
        if creative.get('enabled'):
            print(f"ğŸ§  è¯­ä¹‰ç½‘æ ¼: {output_dir}/semantic_mesh/mesh.json")
        print()
        
    except Exception as e:
        print(f"âš ï¸ è¯»å–å…ƒæ•°æ®å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å®Œæ•´å°è¯´åˆ›ä½œæµç¨‹æµ‹è¯•')
    parser.add_argument('--title', type=str, default='æµ‹è¯•å°è¯´', help='å°è¯´æ ‡é¢˜')
    parser.add_argument('--genre', type=str, default='ç§‘å¹»', help='å°è¯´ç±»å‹')
    parser.add_argument('--theme', type=str, default='æ—¶é—´æ—…è¡Œä¸å¹³è¡Œä¸–ç•Œ', help='ä¸»é¢˜')
    parser.add_argument('--chapters', type=int, default=5, help='ç« èŠ‚æ•°')
    parser.add_argument('--words', type=int, default=2000, help='æ¯ç« å­—æ•°')
    
    args = parser.parse_args()
    
    result = test_full_novel_creation(
        novel_title=args.title,
        genre=args.genre,
        theme=args.theme,
        target_chapters=args.chapters,
        words_per_chapter=args.words
    )
    
    if result:
        print("=" * 70)
        print("ğŸ‰ æµ‹è¯•æˆåŠŸå®Œæˆï¼")
        print("=" * 70)
        return 0
    else:
        print("=" * 70)
        print("âŒ æµ‹è¯•å¤±è´¥")
        print("=" * 70)
        return 1


if __name__ == "__main__":
    sys.exit(main())
