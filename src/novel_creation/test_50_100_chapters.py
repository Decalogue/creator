"""
50-100ç« ç³»ç»Ÿæ€§æµ‹è¯•è„šæœ¬

é€æ­¥æµ‹è¯•ä¸åŒç« èŠ‚æ•°çš„åˆ›ä½œï¼ŒéªŒè¯æ‰€æœ‰ä¼˜åŒ–åŠŸèƒ½ï¼š
1. æ¸è¿›å¼å¤§çº²ç³»ç»Ÿï¼ˆ>=50ç« è‡ªåŠ¨å¯ç”¨ï¼‰
2. åˆ†å±‚æ‘˜è¦ç³»ç»Ÿ
3. å®ä½“é‡è¦æ€§ç®¡ç†
4. é˜¶æ®µæ€§è´¨é‡æ£€æŸ¥ï¼ˆæ¯10ç« ï¼‰
5. è´¨é‡æŒ‡æ ‡è¿½è¸ª
6. å¤§çº²åŠ¨æ€è°ƒæ•´
7. è‡ªé€‚åº”ç”Ÿæˆç­–ç•¥
"""
import sys
import logging
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional

sys.path.insert(0, str(Path(__file__).parent.parent))

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

from novel_creation.react_novel_creator import ReactNovelCreator

logger = logging.getLogger(__name__)


def test_novel_creation(
    novel_title: str,
    genre: str,
    theme: str,
    target_chapters: int,
    words_per_chapter: int = 2048
) -> Optional[Dict[str, Any]]:
    """
    æµ‹è¯•å°è¯´åˆ›ä½œ
    
    Args:
        novel_title: å°è¯´æ ‡é¢˜
        genre: å°è¯´ç±»å‹
        theme: ä¸»é¢˜
        target_chapters: ç›®æ ‡ç« èŠ‚æ•°
        words_per_chapter: æ¯ç« ç›®æ ‡å­—æ•°
    
    Returns:
        æµ‹è¯•ç»“æœ
    """
    print("=" * 80)
    print(f"å¼€å§‹æµ‹è¯•ï¼š{novel_title}")
    print("=" * 80)
    print(f"ğŸ“– ç« èŠ‚æ•°: {target_chapters} ç« ")
    print(f"ğŸ“ æ¯ç« å­—æ•°: {words_per_chapter} å­—")
    print(f"ğŸ“š ç±»å‹: {genre}")
    print(f"ğŸ¯ ä¸»é¢˜: {theme}")
    print()
    
    ***REMOVED*** é€‰æ‹©LLMå®¢æˆ·ç«¯ï¼ˆå¯é€šè¿‡ç¯å¢ƒå˜é‡æˆ–å‚æ•°æ§åˆ¶ï¼‰
    import os
    llm_model = os.getenv("NOVEL_LLM_MODEL", "deepseek_v3_2")  ***REMOVED*** é»˜è®¤ä½¿ç”¨deepseek_v3_2
    
    if llm_model == "gemini_3_flash":
        from llm.chat import gemini_3_flash
        llm_client = gemini_3_flash
        print(f"ä½¿ç”¨LLMæ¨¡å‹: gemini_3_flash")
    else:
        from llm.chat import deepseek_v3_2
        llm_client = deepseek_v3_2
        print(f"ä½¿ç”¨LLMæ¨¡å‹: deepseek_v3_2")
    
    ***REMOVED*** åˆ›å»ºåˆ›ä½œå™¨ï¼ˆå¯ç”¨æ‰€æœ‰ä¼˜åŒ–åŠŸèƒ½ï¼‰
    print("åˆå§‹åŒ–åˆ›ä½œå™¨...")
    try:
        creator = ReactNovelCreator(
            novel_title=novel_title,
            enable_context_offloading=True,
            enable_creative_context=True,
            enable_enhanced_extraction=True,
            enable_unimem=False,
            enable_quality_check=True,
            llm_client=llm_client
        )
        print("âœ… åˆ›ä½œå™¨åˆå§‹åŒ–æˆåŠŸ")
        print()
    except Exception as e:
        print(f"âŒ åˆ›ä½œå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None
    
    ***REMOVED*** å¼€å§‹åˆ›ä½œ
    start_time = datetime.now()
    print("=" * 80)
    print("å¼€å§‹åˆ›ä½œ...")
    print("=" * 80)
    print()
    
    try:
        result = creator.create_novel(
            genre=genre,
            theme=theme,
            target_chapters=target_chapters,
            words_per_chapter=words_per_chapter,
            start_from_chapter=1,
            use_progressive=None  ***REMOVED*** è‡ªåŠ¨é€‰æ‹©ï¼ˆ>=50ç« ä½¿ç”¨æ¸è¿›å¼ï¼‰
        )
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print()
        print("=" * 80)
        print("åˆ›ä½œå®Œæˆï¼")
        print("=" * 80)
        print(f"âœ… æ€»ç« èŠ‚æ•°: {result.get('total_chapters', 0)}")
        print(f"âœ… æ€»å­—æ•°: {result.get('total_words', 0):,} å­—")
        print(f"âœ… è€—æ—¶: {duration:.1f} ç§’ ({duration/60:.1f} åˆ†é’Ÿ)")
        print(f"âœ… è¾“å‡ºç›®å½•: {result.get('output_dir', 'N/A')}")
        print()
        
        ***REMOVED*** éªŒè¯ä¼˜åŒ–åŠŸèƒ½
        print("=" * 80)
        print("éªŒè¯ä¼˜åŒ–åŠŸèƒ½...")
        print("=" * 80)
        print()
        
        ***REMOVED*** 1. æ£€æŸ¥å¤§çº²ç±»å‹
        plan = creator.metadata.get("plan", {})
        plan_type = plan.get("plan_type", "onetime")
        print(f"ğŸ“‹ å¤§çº²ç±»å‹: {plan_type}")
        if plan_type == "progressive":
            print("  âœ… ä½¿ç”¨æ¸è¿›å¼å¤§çº²ç”Ÿæˆï¼ˆè‡ªåŠ¨å¯ç”¨ï¼‰")
            phases = plan.get("phases", [])
            print(f"  âœ… å·²ç”Ÿæˆé˜¶æ®µæ•°: {len(phases)}")
            overall = plan.get("overall", {})
            if overall:
                print(f"  âœ… æ•´ä½“å¤§çº²å·²ç”Ÿæˆï¼ˆåŒ…å« {len(overall.get('key_plot_points', []))} ä¸ªå…³é”®è½¬æŠ˜ç‚¹ï¼‰")
        else:
            print("  â„¹ï¸  ä½¿ç”¨ä¸€æ¬¡æ€§å¤§çº²ç”Ÿæˆï¼ˆç« èŠ‚æ•° < 50ï¼Œç¬¦åˆé¢„æœŸï¼‰")
        print()
        
        ***REMOVED*** 2. æ£€æŸ¥å®ä½“ç³»ç»Ÿ
        if creator.enable_creative_context and creator.semantic_mesh:
            entities_count = len(creator.semantic_mesh.entities)
            relations_count = len(creator.semantic_mesh.relations)
            print(f"ğŸ”— è¯­ä¹‰ç½‘æ ¼:")
            print(f"  âœ… å®ä½“æ€»æ•°: {entities_count}")
            print(f"  âœ… å…³ç³»æ€»æ•°: {relations_count}")
            
            ***REMOVED*** æ£€æŸ¥å®ä½“é‡è¦æ€§å…ƒæ•°æ®
            entities_with_importance = sum(
                1 for e in creator.semantic_mesh.entities.values()
                if e.metadata.get('appearance_count', 0) > 0
            )
            print(f"  âœ… å·²æ›´æ–°é‡è¦æ€§çš„å®ä½“: {entities_with_importance}")
            
            ***REMOVED*** æ£€æŸ¥å…³é”®å®ä½“
            key_entities = [
                e for e in creator.semantic_mesh.entities.values()
                if e.metadata.get('is_key', False)
            ]
            print(f"  âœ… å…³é”®å®ä½“æ•°: {len(key_entities)}")
            print()
        
        ***REMOVED*** 3. æ£€æŸ¥é˜¶æ®µæ€§è´¨é‡æ£€æŸ¥
        periodic_checks = creator.metadata.get("periodic_quality_checks", [])
        print(f"ğŸ“Š é˜¶æ®µæ€§è´¨é‡æ£€æŸ¥:")
        print(f"  âœ… æ£€æŸ¥æ¬¡æ•°: {len(periodic_checks)}")
        if periodic_checks:
            for check in periodic_checks:
                scores = check.get("scores", {})
                overall = scores.get("overall", 0)
                needs_attention = check.get("needs_attention", False)
                status = "âš ï¸  éœ€è¦å…³æ³¨" if needs_attention else "âœ… æ­£å¸¸"
                print(f"  {status} {check.get('chapter_range', 'N/A')}: ç»¼åˆè¯„åˆ† {overall:.2f}")
        print()
        
        ***REMOVED*** 4. æ£€æŸ¥è´¨é‡æŒ‡æ ‡è¿½è¸ª
        quality_tracker = creator.metadata.get("quality_tracker", {})
        quality_history = quality_tracker.get("chapter_quality_history", [])
        if quality_history:
            print(f"ğŸ“ˆ è´¨é‡æŒ‡æ ‡è¿½è¸ª:")
            print(f"  âœ… å·²è®°å½•ç« èŠ‚æ•°: {len(quality_history)}")
            
            ***REMOVED*** è®¡ç®—å¹³å‡æŒ‡æ ‡
            avg_word_control = sum(m.get("word_control_score", 0) for m in quality_history) / len(quality_history)
            avg_issues = sum(m.get("quality_issues", 0) for m in quality_history) / len(quality_history)
            print(f"  âœ… å¹³å‡å­—æ•°æ§åˆ¶å¾—åˆ†: {avg_word_control:.2f}")
            print(f"  âœ… å¹³å‡è´¨é‡é—®é¢˜æ•°: {avg_issues:.2f}")
            
            ***REMOVED*** è´¨é‡è¶‹åŠ¿
            trends = quality_tracker.get("quality_trends", {})
            if trends:
                print(f"  âœ… è´¨é‡è¶‹åŠ¿æ•°æ®ç‚¹: {sum(len(v) for v in trends.values())}")
        print()
        
        ***REMOVED*** 5. æ£€æŸ¥ç« èŠ‚è´¨é‡ç»Ÿè®¡
        print("ğŸ“Š ç« èŠ‚è´¨é‡ç»Ÿè®¡:")
        word_stats = []
        for chapter in creator.chapters:
            actual_words = chapter.metadata.get("actual_words", len(chapter.content))
            target_words = chapter.metadata.get("target_words", words_per_chapter)
            word_diff_percent = chapter.metadata.get("word_diff_percent", 0)
            word_stats.append({
                "chapter": chapter.chapter_number,
                "actual": actual_words,
                "target": target_words,
                "diff_percent": word_diff_percent
            })
        
        if word_stats:
            avg_words = sum(s["actual"] for s in word_stats) / len(word_stats)
            avg_diff_percent = sum(abs(s["diff_percent"]) for s in word_stats) / len(word_stats)
            print(f"  âœ… å¹³å‡å­—æ•°: {avg_words:.0f} å­—")
            print(f"  âœ… å¹³å‡å­—æ•°åå·®: {avg_diff_percent:.1f}%")
            
            ***REMOVED*** å­—æ•°åˆ†å¸ƒ
            within_target = sum(1 for s in word_stats if abs(s["diff_percent"]) <= 10)
            within_limit = sum(1 for s in word_stats if s["actual"] <= 3000)
            print(f"  âœ… å­—æ•°åœ¨ç›®æ ‡Â±10%å†…: {within_target}/{len(word_stats)} ({within_target/len(word_stats)*100:.1f}%)")
            print(f"  âœ… å­—æ•°åœ¨3000å­—ä¸Šé™å†…: {within_limit}/{len(word_stats)} ({within_limit/len(word_stats)*100:.1f}%)")
        print()
        
        ***REMOVED*** 6. è·å–è´¨é‡æ‘˜è¦
        quality_summary = creator.get_quality_summary()
        if quality_summary and "message" not in quality_summary:
            print("ğŸ“ˆ è´¨é‡æ‘˜è¦:")
            avg_metrics = quality_summary.get("average_metrics", {})
            print(f"  âœ… å¹³å‡å­—æ•°æ§åˆ¶å¾—åˆ†: {avg_metrics.get('word_control_score', 0):.2f}")
            print(f"  âœ… å¹³å‡è´¨é‡é—®é¢˜æ•°: {avg_metrics.get('quality_issues', 0):.2f}")
            
            trends = quality_summary.get("quality_trends", {})
            if trends:
                print(f"  âœ… è´¨é‡è¶‹åŠ¿:")
                for metric_name, trend_data in trends.items():
                    current = trend_data.get("current", 0)
                    trend = trend_data.get("trend", "stable")
                    trend_icon = "ğŸ“ˆ" if trend == "improving" else "ğŸ“‰" if trend == "declining" else "â¡ï¸"
                    print(f"    {trend_icon} {metric_name}: {current:.2f} ({trend})")
        print()
        
        print("=" * 80)
        print("âœ… æ‰€æœ‰åŠŸèƒ½éªŒè¯å®Œæˆï¼")
        print("=" * 80)
        
        return {
            "result": result,
            "creator": creator,
            "duration": duration,
            "plan_type": plan_type,
            "periodic_checks": periodic_checks,
            "quality_summary": quality_summary
        }
        
    except Exception as e:
        print()
        print("=" * 80)
        print("âŒ åˆ›ä½œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯")
        print("=" * 80)
        print(f"é”™è¯¯ä¿¡æ¯: {e}")
        import traceback
        traceback.print_exc()
        return None


def run_progressive_tests():
    """
    é€æ­¥æµ‹è¯•ä¸åŒç« èŠ‚æ•°ï¼š50, 60, 70, 80, 90, 100ç« 
    """
    test_cases = [
        {"chapters": 50, "title": "50ç« æ¸è¿›å¼å¤§çº²æµ‹è¯•"},
        {"chapters": 60, "title": "60ç« æ¸è¿›å¼å¤§çº²æµ‹è¯•"},
        {"chapters": 70, "title": "70ç« æ¸è¿›å¼å¤§çº²æµ‹è¯•"},
        {"chapters": 80, "title": "80ç« æ¸è¿›å¼å¤§çº²æµ‹è¯•"},
        {"chapters": 90, "title": "90ç« æ¸è¿›å¼å¤§çº²æµ‹è¯•"},
        {"chapters": 100, "title": "100ç« æ¸è¿›å¼å¤§çº²æµ‹è¯•"},
    ]
    
    results = []
    
    for test_case in test_cases:
        chapters = test_case["chapters"]
        title = test_case["title"]
        
        print("\n" + "=" * 80)
        print(f"å¼€å§‹æµ‹è¯• {chapters} ç« ")
        print("=" * 80)
        print()
        
        result = test_novel_creation(
            novel_title=title,
            genre="éƒ½å¸‚",
            theme="ç³»ç»Ÿæ–‡ã€æ‰“è„¸è£…é€¼",
            target_chapters=chapters,
            words_per_chapter=2048
        )
        
        if result:
            results.append({
                "chapters": chapters,
                "title": title,
                "success": True,
                "duration": result["duration"],
                "plan_type": result["plan_type"],
                "periodic_checks_count": len(result["periodic_checks"]),
                "quality_summary": result["quality_summary"]
            })
        else:
            results.append({
                "chapters": chapters,
                "title": title,
                "success": False
            })
        
        print(f"\nâœ… {chapters} ç« æµ‹è¯•å®Œæˆ\n")
        print("ç­‰å¾…5ç§’åç»§ç»­ä¸‹ä¸€ä¸ªæµ‹è¯•...")
        import time
        time.sleep(5)
    
    ***REMOVED*** è¾“å‡ºæ€»ç»“
    print("\n" + "=" * 80)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    print()
    
    for r in results:
        if r["success"]:
            print(f"âœ… {r['chapters']}ç« : æˆåŠŸ (è€—æ—¶: {r['duration']/60:.1f}åˆ†é’Ÿ, å¤§çº²ç±»å‹: {r['plan_type']}, è´¨é‡æ£€æŸ¥: {r['periodic_checks_count']}æ¬¡)")
        else:
            print(f"âŒ {r['chapters']}ç« : å¤±è´¥")
    
    return results


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="50-100ç« ç³»ç»Ÿæ€§æµ‹è¯•")
    parser.add_argument("--chapters", type=int, default=50, help="æµ‹è¯•ç« èŠ‚æ•°ï¼ˆé»˜è®¤50ç« ï¼‰")
    parser.add_argument("--words", type=int, default=2048, help="æ¯ç« ç›®æ ‡å­—æ•°ï¼ˆé»˜è®¤2048å­—ï¼‰")
    parser.add_argument("--title", type=str, default=None, help="å°è¯´æ ‡é¢˜ï¼ˆé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰")
    parser.add_argument("--genre", type=str, default="éƒ½å¸‚", help="å°è¯´ç±»å‹")
    parser.add_argument("--theme", type=str, default="ç³»ç»Ÿæ–‡ã€æ‰“è„¸è£…é€¼", help="ä¸»é¢˜")
    parser.add_argument("--progressive", action="store_true", help="è¿è¡Œé€æ­¥æµ‹è¯•ï¼ˆ50, 60, 70, 80, 90, 100ç« ï¼‰")
    
    args = parser.parse_args()
    
    if args.progressive:
        run_progressive_tests()
    else:
        title = args.title or f"{args.chapters}ç« ç³»ç»Ÿæ€§æµ‹è¯•"
        test_novel_creation(
            novel_title=title,
            genre=args.genre,
            theme=args.theme,
            target_chapters=args.chapters,
            words_per_chapter=args.words
        )
