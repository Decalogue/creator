"""
100ç« å°è¯´ä¼˜åŒ–åŠŸèƒ½æµ‹è¯•è„šæœ¬

éªŒè¯ä»¥ä¸‹ä¼˜åŒ–ï¼š
1. å®ä½“é‡è¦æ€§è¯„åˆ†å’Œåˆ†å±‚ä¼ é€’
2. æ¸è¿›å¼å¤§çº²ç”Ÿæˆ
3. åˆ†å±‚ç« èŠ‚æ‘˜è¦
"""
import sys
import logging
from pathlib import Path
from datetime import datetime
from typing import Optional

sys.path.insert(0, str(Path(__file__).parent.parent))

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

from novel_creation.react_novel_creator import ReactNovelCreator

logger = logging.getLogger(__name__)


def test_100_chapter_optimizations(
    novel_title: str = "100ç« ä¼˜åŒ–æµ‹è¯•å°è¯´",
    genre: str = "éƒ½å¸‚",
    theme: str = "ç³»ç»Ÿæ–‡ã€æ‰“è„¸è£…é€¼",
    target_chapters: int = 5,  ***REMOVED*** å…ˆæµ‹è¯•5ç« ï¼ŒéªŒè¯åŠŸèƒ½æ­£å¸¸
    words_per_chapter: int = 2000,
    use_progressive: Optional[bool] = None  ***REMOVED*** None = è‡ªåŠ¨é€‰æ‹©ï¼ŒTrue = å¼ºåˆ¶å¯ç”¨ï¼ŒFalse = å¼ºåˆ¶ç¦ç”¨
):
    """
    æµ‹è¯•100ç« å°è¯´ä¼˜åŒ–åŠŸèƒ½
    
    Args:
        novel_title: å°è¯´æ ‡é¢˜
        genre: å°è¯´ç±»å‹
        theme: ä¸»é¢˜
        target_chapters: ç›®æ ‡ç« èŠ‚æ•°ï¼ˆ5ç« å¿«é€ŸéªŒè¯ï¼Œæˆ–20ç« éªŒè¯é˜¶æ®µæ‘˜è¦ï¼‰
        words_per_chapter: æ¯ç« ç›®æ ‡å­—æ•°
    """
    print("=" * 70)
    print("100ç« å°è¯´ä¼˜åŒ–åŠŸèƒ½æµ‹è¯•")
    print("=" * 70)
    print()
    print(f"ğŸ“– å°è¯´æ ‡é¢˜: {novel_title}")
    print(f"ğŸ“š ç±»å‹: {genre}")
    print(f"ğŸ¯ ä¸»é¢˜: {theme}")
    print(f"ğŸ“‘ ç« èŠ‚æ•°: {target_chapters} ç« ")
    print(f"ğŸ“ æ¯ç« å­—æ•°: {words_per_chapter} å­—")
    print()
    print("ğŸ” æµ‹è¯•ä¼˜åŒ–åŠŸèƒ½ï¼š")
    print("  âœ… Phase 1: å®ä½“é‡è¦æ€§è¯„åˆ†å’Œåˆ†å±‚ä¼ é€’")
    print("  âœ… Phase 2: æ¸è¿›å¼å¤§çº²ç”Ÿæˆï¼ˆ>=50ç« è‡ªåŠ¨å¯ç”¨ï¼‰")
    print("  âœ… Phase 3: åˆ†å±‚ç« èŠ‚æ‘˜è¦")
    print()
    
    ***REMOVED*** åˆ›å»ºåˆ›ä½œå™¨ï¼ˆå¯ç”¨æ‰€æœ‰ä¼˜åŒ–åŠŸèƒ½ï¼‰
    print("=" * 70)
    print("åˆå§‹åŒ–åˆ›ä½œå™¨...")
    print("=" * 70)
    
    try:
        creator = ReactNovelCreator(
            novel_title=novel_title,
            enable_context_offloading=True,
            enable_creative_context=True,
            enable_enhanced_extraction=True,
            enable_unimem=False,
            enable_quality_check=True
        )
        print("âœ… åˆ›ä½œå™¨åˆå§‹åŒ–æˆåŠŸ")
        print()
    except Exception as e:
        print(f"âŒ åˆ›ä½œå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None
    
    ***REMOVED*** å¼€å§‹åˆ›ä½œ
    print("=" * 70)
    print("å¼€å§‹åˆ›ä½œ...")
    print("=" * 70)
    print()
    
    start_time = datetime.now()
    
    try:
        result = creator.create_novel(
            genre=genre,
            theme=theme,
            target_chapters=target_chapters,
            words_per_chapter=words_per_chapter,
            start_from_chapter=1,
            use_progressive=use_progressive
        )
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print()
        print("=" * 70)
        print("åˆ›ä½œå®Œæˆï¼")
        print("=" * 70)
        print()
        print(f"âœ… æ€»ç« èŠ‚æ•°: {result.get('total_chapters', 0)}")
        print(f"âœ… æ€»å­—æ•°: {result.get('total_words', 0):,} å­—")
        print(f"âœ… è€—æ—¶: {duration:.1f} ç§’")
        print(f"âœ… è¾“å‡ºç›®å½•: {result.get('output_dir', 'N/A')}")
        print()
        
        ***REMOVED*** éªŒè¯ä¼˜åŒ–åŠŸèƒ½
        print("=" * 70)
        print("éªŒè¯ä¼˜åŒ–åŠŸèƒ½...")
        print("=" * 70)
        print()
        
        ***REMOVED*** 1. æ£€æŸ¥å¤§çº²ç±»å‹ï¼ˆæ¸è¿›å¼ vs ä¸€æ¬¡æ€§ï¼‰
        plan = creator.metadata.get("plan", {})
        plan_type = plan.get("plan_type", "onetime")
        print(f"ğŸ“‹ å¤§çº²ç±»å‹: {plan_type}")
        if plan_type == "progressive":
            print("  âœ… ä½¿ç”¨æ¸è¿›å¼å¤§çº²ç”Ÿæˆï¼ˆè‡ªåŠ¨å¯ç”¨ï¼‰")
            phases = plan.get("phases", [])
            print(f"  âœ… å·²ç”Ÿæˆé˜¶æ®µæ•°: {len(phases)}")
            overall = plan.get("overall", {})
            if overall:
                print(f"  âœ… æ•´ä½“å¤§çº²å·²ç”Ÿæˆï¼ˆåŒ…å« {len(overall.get('key_plot_points', []))} ä¸ªå…³é”®è½¬æŠ˜ç‚¹ï¼‰")
        else:
            print("  â„¹ï¸  ä½¿ç”¨ä¸€æ¬¡æ€§å¤§çº²ç”Ÿæˆï¼ˆç« èŠ‚æ•° < 50ï¼Œç¬¦åˆé¢„æœŸï¼‰")
        print()
        
        ***REMOVED*** 2. æ£€æŸ¥å®ä½“ç³»ç»Ÿ
        if creator.enable_creative_context and creator.semantic_mesh:
            entities_count = len(creator.semantic_mesh.entities)
            relations_count = len(creator.semantic_mesh.relations)
            print(f"ğŸ”— è¯­ä¹‰ç½‘æ ¼:")
            print(f"  âœ… å®ä½“æ€»æ•°: {entities_count}")
            print(f"  âœ… å…³ç³»æ€»æ•°: {relations_count}")
            
            ***REMOVED*** æ£€æŸ¥å®ä½“é‡è¦æ€§å…ƒæ•°æ®
            entities_with_importance = sum(
                1 for e in creator.semantic_mesh.entities.values()
                if e.metadata.get('appearance_count', 0) > 0
            )
            print(f"  âœ… å·²æ›´æ–°é‡è¦æ€§çš„å®ä½“: {entities_with_importance}")
            print()
            
            ***REMOVED*** æ£€æŸ¥å…³é”®å®ä½“
            key_entities = [
                e for e in creator.semantic_mesh.entities.values()
                if e.metadata.get('is_key', False)
            ]
            print(f"  âœ… å…³é”®å®ä½“æ•°: {len(key_entities)}")
            if key_entities:
                print("  å…³é”®å®ä½“åˆ—è¡¨:")
                for entity in key_entities[:5]:  ***REMOVED*** åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"    - {entity.name} ({entity.type.value})")
            print()
        
        ***REMOVED*** 3. æ£€æŸ¥åˆ†å±‚æ‘˜è¦ï¼ˆå¦‚æœç« èŠ‚æ•°è¶³å¤Ÿï¼‰
        if target_chapters >= 20:
            print("ğŸ“‘ åˆ†å±‚æ‘˜è¦éªŒè¯:")
            ***REMOVED*** æ£€æŸ¥æœ€è¿‘ç« èŠ‚æ˜¯å¦åŒ…å«æ‘˜è¦
            recent_chapters = creator.chapters[-5:] if len(creator.chapters) >= 5 else creator.chapters
            has_summaries = all(ch.summary for ch in recent_chapters)
            print(f"  âœ… æœ€è¿‘ç« èŠ‚æ‘˜è¦å®Œæ•´æ€§: {'æ˜¯' if has_summaries else 'å¦'}")
            
            ***REMOVED*** æ£€æŸ¥é˜¶æ®µæ‘˜è¦ï¼ˆå¦‚æœä½¿ç”¨æ¸è¿›å¼ï¼‰
            if plan_type == "progressive":
                phases = plan.get("phases", [])
                phases_with_summary = sum(1 for p in phases if p.get("phase_summary"))
                print(f"  âœ… å·²ç”Ÿæˆé˜¶æ®µæ‘˜è¦æ•°: {phases_with_summary}")
            print()
        
        ***REMOVED*** 4. æ£€æŸ¥ç« èŠ‚è´¨é‡
        print("ğŸ“Š ç« èŠ‚è´¨é‡ç»Ÿè®¡:")
        word_stats = []
        for chapter in creator.chapters:
            actual_words = chapter.metadata.get("actual_words", len(chapter.content))
            target_words = chapter.metadata.get("target_words", words_per_chapter)
            word_diff_percent = chapter.metadata.get("word_diff_percent", 0)
            word_stats.append({
                "chapter": chapter.chapter_number,
                "actual": actual_words,
                "target": target_words,
                "diff_percent": word_diff_percent
            })
        
        avg_words = sum(s["actual"] for s in word_stats) / len(word_stats) if word_stats else 0
        avg_diff_percent = sum(abs(s["diff_percent"]) for s in word_stats) / len(word_stats) if word_stats else 0
        
        print(f"  âœ… å¹³å‡å­—æ•°: {avg_words:.0f} å­—")
        print(f"  âœ… å¹³å‡å­—æ•°åå·®: {avg_diff_percent:.1f}%")
        print()
        
        print("=" * 70)
        print("âœ… æ‰€æœ‰ä¼˜åŒ–åŠŸèƒ½éªŒè¯å®Œæˆï¼")
        print("=" * 70)
        
        return result
        
    except Exception as e:
        print()
        print("=" * 70)
        print("âŒ åˆ›ä½œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯")
        print("=" * 70)
        print(f"é”™è¯¯ä¿¡æ¯: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="æµ‹è¯•100ç« å°è¯´ä¼˜åŒ–åŠŸèƒ½")
    parser.add_argument("--chapters", type=int, default=5, help="æµ‹è¯•ç« èŠ‚æ•°ï¼ˆé»˜è®¤5ç« ï¼‰")
    parser.add_argument("--words", type=int, default=2000, help="æ¯ç« ç›®æ ‡å­—æ•°ï¼ˆé»˜è®¤2000å­—ï¼‰")
    parser.add_argument("--title", type=str, default="100ç« ä¼˜åŒ–æµ‹è¯•å°è¯´", help="å°è¯´æ ‡é¢˜")
    parser.add_argument("--genre", type=str, default="éƒ½å¸‚", help="å°è¯´ç±»å‹")
    parser.add_argument("--theme", type=str, default="ç³»ç»Ÿæ–‡ã€æ‰“è„¸è£…é€¼", help="ä¸»é¢˜")
    parser.add_argument("--progressive", action="store_true", help="å¼ºåˆ¶å¯ç”¨æ¸è¿›å¼å¤§çº²ï¼ˆé»˜è®¤ï¼š>=50ç« è‡ªåŠ¨å¯ç”¨ï¼‰")
    parser.add_argument("--no-progressive", action="store_true", help="å¼ºåˆ¶ç¦ç”¨æ¸è¿›å¼å¤§çº²")
    
    args = parser.parse_args()
    
    ***REMOVED*** å¤„ç†æ¸è¿›å¼å¤§çº²é€‰é¡¹
    use_progressive = None
    if args.progressive:
        use_progressive = True
    elif args.no_progressive:
        use_progressive = False
    
    test_100_chapter_optimizations(
        novel_title=args.title,
        genre=args.genre,
        theme=args.theme,
        target_chapters=args.chapters,
        words_per_chapter=args.words,
        use_progressive=use_progressive
    )
